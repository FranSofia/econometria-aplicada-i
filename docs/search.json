[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa del Curso",
    "section": "",
    "text": "Curso: Econometría Aplicada I\nInstitución: Universidad de Chile - FEN (Postgrado)\nProfesores: Mariana Zerpa R. - Esteban Puentes E.\nAyudante: Camila Carrasco G.\nSemestre: Primavera II (noviembre-enero)"
  },
  {
    "objectID": "syllabus.html#información-general",
    "href": "syllabus.html#información-general",
    "title": "Programa del Curso",
    "section": "",
    "text": "Curso: Econometría Aplicada I\nInstitución: Universidad de Chile - FEN (Postgrado)\nProfesores: Mariana Zerpa R. - Esteban Puentes E.\nAyudante: Camila Carrasco G.\nSemestre: Primavera II (noviembre-enero)"
  },
  {
    "objectID": "syllabus.html#descripción-y-objetivos",
    "href": "syllabus.html#descripción-y-objetivos",
    "title": "Programa del Curso",
    "section": "Descripción y Objetivos",
    "text": "Descripción y Objetivos\nEl curso busca introducir la aplicación de herramientas de microeconometría, con énfasis en la estimación de efectos causales. Se cubren métodos como variables instrumentales, regresión discontinua y diferencias en diferencias."
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa del Curso",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\n\nInstrumento\nPonderación\nFormato\nFecha\n\n\n\n\nTareas (3)\n25%\nPráctico (Stata/R)\n15 Dic, 05 Ene, 19 Ene\n\n\nControles (4)\n25%\nHíbrido (Lecturas)\n13 Dic, 19 Dic, 09 Ene, 16 Ene\n\n\nExamen\n50%\nPresencial\n24 de Enero"
  },
  {
    "objectID": "syllabus.html#contenidos",
    "href": "syllabus.html#contenidos",
    "title": "Programa del Curso",
    "section": "Contenidos",
    "text": "Contenidos\n\nMétodos Causales: Endogeneidad, Evaluación Experimental, Selección en Observables.\nVariables Instrumentales (IV): Identificación y estimación.\nRegresión Discontinua (RDD): Diseños nítidos y borrosos.\nDatos de Panel: Efectos Fijos. Diferencias en Diferencias (DiD): y Estudios de Eventos.\nMatching"
  },
  {
    "objectID": "syllabus.html#bibliografía-principal",
    "href": "syllabus.html#bibliografía-principal",
    "title": "Programa del Curso",
    "section": "Bibliografía Principal",
    "text": "Bibliografía Principal\n\nMostly Harmless Econometrics (Angrist & Pischke)\nCausal Inference: The Mixtape (Cunningham)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometría Aplicada I",
    "section": "",
    "text": "Bienvenida/e/o. Este sitio recopila mis apuntes y ejercicios del curso Econometría Aplicada I del Magíster en Análisis Económico weekend en la Facultad de Economía y Negocios de la Universidad de Chile.\nAunque el curso se dicta oficialmente utilizando Stata, este repositorio contiene la replicación de los laboratorios y tareas utilizando R, como ejercicio personal de traducción de código y profundización en los métodos."
  },
  {
    "objectID": "index.html#objetivos-del-curso",
    "href": "index.html#objetivos-del-curso",
    "title": "Econometría Aplicada I",
    "section": "Objetivos del curso",
    "text": "Objetivos del curso\n\nGeneral:\n\nQue cada estudiante implemente los principales y más recientes métodos de estimacién y test estadísticos utilizados en microeconometría, de acuerdo a la pregunta de investigación que se enfrente y los datos disponibles con énfasis en la estimación de efectos causales\n\nEspecíficos:\n\nProfundizar de manera teórica y analítica los principales modelos utilizados en microeconometría\nImplementar de manera práctica estos modelos, identificando la técnica más pertinente según la pregunta de investigación y datos disponibles\nInterpretar, evaluar y reportar los resultados de estimaciones microeconométricas"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "sesiones/01-causalidad.html",
    "href": "sesiones/01-causalidad.html",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "",
    "text": "Esta sesión introduce el problema fundamental de la inferencia causal y establece el marco teórico de los Resultados Potenciales (Rubin Causal Model). Se parte discutiendo por qué la correlación no implica causalidad, sobre el sesgo de selección y cómo los experimentos aleatorios (RCT) resuelven el problema del sesgo de selección."
  },
  {
    "objectID": "sesiones/01-causalidad.html#causalidad-vs.-correlación",
    "href": "sesiones/01-causalidad.html#causalidad-vs.-correlación",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "1.1 Causalidad vs. Correlación",
    "text": "1.1 Causalidad vs. Correlación\nComo ya vimos, muchas relaciones entre variables pueden confundirse, sobre todo las correlaciones con las relaciones causales. Una forma típica es lo que se conoce como correlación espúrea. El caracter espurio de una correlación está dado por la alta asociación (o generalmente por la alta) entre variables y que, en virtud de ella, se interprete una relación de necesidad, o peor, de causalidad.\nUn ejemplo clásico de correlación espuria:\n\n\n\n\n\n\nEjemplo: Nicolas Cage y Ahogamientos Existe una correlación del 66% entre las películas de Nicolas Cage y la gente que se ahoga en piscinas. No obstante, sabemos que Nicolás Cage y sus películas no causan que más personas se ahoguen. Esto ilustra que \\(Corr(X,Y) \\neq 0\\) no implica causalidad, por más fuerte que sea el grado de asociación.\n\n\n\n\n\n\n\n\nCorrelación espuria\n\n\n\n\nConfundir una correlación (y peor aún: una espúrea) con una relación causal, puede llevar a errores graves. Por ejemplo, en Mostly Harmless Econometrics (Angrist y Pischke, 2008) se muestra cómo hay una relación entre ir (o no) al hospital y el grado de “salud subjetiva”1 reportado. Los datos son los siguientes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabla 1: Comparación de medias en EE.UU. (NHIS)\n\n\nGrupo\nN\n\nResultados de Salud\n\n\n\nSalud Promedio (1=Excelente, 5=Muy Mal)\nError Est.\n\n\n\n\nHospital\n7,774\n2.79\n0.014\n\n\nNo Hospital\n90,049\n2.07\n0.003\n\n\n\nFuente: Angrist & Pischke (2008). Diferencia de medias: 0.71 (t=58.9).\n\n\n\n\n\n\n\n\nComo se puede observar, la salud promedio de las personas que no asisten al hospital reportan que, en promedio, tienen un estado de salud mejor a los que asisten (\\(2{,}79 &gt; 2{,}07\\)), pues el promedio de los que no asisten al hospital es más cercano al 1 (“Excelente salud”) que los que sí asisten. Pero, ¿esto significa que asistir al hospital empeora la salud? Suena ridículo dicho así (o quizás no), pero lo cierto es que este tipo de relaciones se suelen establecer. Es más, ¿por qué suena ridiculo? ¿Qué es lo raro en que las personas que van al hospital tienen en promedio problemas de salud mas graves? En realidad, esto es así, pero eso no significa que ir a un hospital empeora la salud, es decir, no hay una relación causal. Pero, ¿por qué no la hay?\nEl motivo de que no la haya se puede sintetizar en el siguiente concepto: sesgo de selección. En primer lugar, si miramos las características de cada grupo (quienes asisten o no al hospital), que son pre-existentes a ir o no al hospital y a declarar un buen o mal estado de salud, probablemente van a ser muy diferentes. Por ejemplo, aún no hemos visto si tienen diferencias de edad, el contexto socioeconómico, indicadores de salud previos a la atención, etc. Sin observar todo eso, es dificil afirmar que ir al hospital empeora la salud. En segundo lugar, algo que probablemente se considere de sentido común, es que probablemente las personas asisten al hospital lo hacen justamente porque tienen problemas de salud. En cambio, probablemente no tienen problemas de salud, y por eso no van a un hospital. Es decir, las personas que se atienden en un hospital son distintas a aquellas que eligen no hacerlo, pues se autoseleccionan en nuestro tratamiento. A todo esto, le llamamos un problema de sesgo de selección. Por cierto, la evidencia de Angrist y Pischke (2008) también se puede observar para Chile si vemos los datos de la Casen 20152:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabla 2: Evidencia similar para Chile (CASEN 2015)\n\n\nGrupo\nN\n\nResultados de Salud\n\n\n\nSalud Promedio (1=Muy Mal, 7=Muy Bien)\nError Est.\n\n\n\n\nHospital\n4,849\n4.23\n0.022\n\n\nNo Hospital\n40,816\n4.93\n0.007\n\n\n\nFuente: Elaboración propia con CASEN 2015. Diferencia de medias: 0.70 (t=33.1).\n\n\n\n\n\n\n\n\n\n1.1.1 El problema de Selección (Formalización)\nHasta ahora hemos hablado intuitivamente sobre por qué comparar promedios directos nos lleva a errores. Para ser rigurosos, debemos formalizar esto utilizando el lenguaje de los Resultados Potenciales (Potential Outcomes), el bloque fundamental de la econometría moderna. Con ello, nos adelantaremos unos pasos, pero después lo retomamos de nuevo.\nSiguiendo a Angrist y Pischke (2008), imaginemos que el tratamiento (ir al hospital) es una variable binaria \\(D_i = \\{0, 1\\}\\). El interés radica en saber si el resultado de salud \\(Y_i\\) es afectado por este tratamiento.\nEntonces, para cada individuo \\(i\\), existen dos “vidas paralelas” o resultados potenciales:\n\n\\(Y_{1i}\\): El estado de salud si la persona va al hospital (\\(D_i=1\\)).\n\\(Y_{0i}\\): El estado de salud si la persona no va al hospital (\\(D_i=0\\)).\n\nEl efecto causal para un individuo sería la diferencia entre estos dos estados: \\(\\tau_i = Y_{1i} - Y_{0i}\\). El problema fundamental de la inferencia causal es que nunca podemos observar ambos resultados simultáneamente para la misma persona. Solo observamos lo que realmente ocurrió:\n\\[\nY_i = \\begin{cases}\nY_{1i} & \\text{si } D_i = 1 \\\\\nY_{0i} & \\text{si } D_i = 0\n\\end{cases}\n\\]\nLo cual se puede reescribir como: \\[Y_i = Y_{0i} + (Y_{1i} - Y_{0i})D_i\\]\n\n1.1.1.1 Descomposición de la Diferencia Observada\nCuando ingenuamente comparamos el promedio de salud de los hospitalizados con los no hospitalizados, estamos calculando la Diferencia de Medias Observada. Matemáticamente, esto se descompone en dos partes muy distintas:\n\\[\n\\underbrace{E[Y_i | D_i=1] - E[Y_i | D_i=0]}_{\\text{Diferencia Observada}} = \\underbrace{E[Y_{1i} - Y_{0i} | D_i=1]}_{\\text{ATT}} + \\underbrace{E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]}_{\\text{Sesgo de Selección}}\n\\]\n\nEl Efecto Promedio en los Tratados (ATT): \\(E[Y_{1i} - Y_{0i} | D_i=1]\\). Esto es lo que queremos medir: ¿cuánto mejoró (o empeoró) la salud de quienes fueron al hospital gracias a ir al hospital?\nEl Sesgo de Selección: \\(E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]\\). Esta es la parte “sucia”. Es la diferencia en la salud base (\\(Y_{0i}\\)) entre quienes fueron al hospital y quienes no.\n\nVolviendo a nuestro ejemplo: como las personas que van al hospital suelen estar más enfermas de base, su \\(Y_{0i}\\) (salud sin tratamiento) es mucho peor que el de las personas que se quedan en casa. Esto hace que el término de Sesgo de Selección sea negativo y muy grande, opacando cualquier efecto positivo (ATT) que el hospital pudiera tener.\nEn resumen, la “Comparación Naive” mezcla el efecto causal con la autoselección de los individuos. El objetivo de la econometría (y de los RCT que veremos a continuación) es eliminar este segundo término para aislar el efecto causal verdadero.\n\n\n\n1.1.2 Sintesis pre validez del análisis empírico\nEntonces, volviendo al problema de la causalidad (y la correlación). Sabiendo que el problema del sesgo de selección (selection bias) subyace a la dificultad de identificar el carácter causal de una relación entre variables, veremos que la relación entre variables y la naturaleza entre estas es fundamental para identificar efectos causales. Por ejemplo, para el diseño de políticas públicas, va ser distinto lo que ocurre con \\(Y\\) si una política altera el valor de \\(X\\) si:\n\n\\(X \\implies Y\\)\n\\(Z \\implies Y \\quad \\wedge \\quad Z \\implies X\\)\n\\(Y \\implies X\\)\n\nEsquemáticamente, la distintas relaciones entre \\(X,Y\\), se pueden resumir así:\n\n\n\n\n\nRelaciones de causalidad\n\n\n\n\nEn este contexto, la correlación entre \\(X\\) e \\(Y\\) no es muy informativa sobre el efecto causal de cambiar \\(X\\) en \\(Y\\). Para solucionar esto, vamos a arrancar el curso con el ideal experimental\nEn esta sesión, veremos que los datos experimentales son muy útiles para establecer causaldiad. A su vez, a lo largo de todo el curso, veremos como pensar en el experimento ideal nos puede orientar y ayudar a encontrar relaciones causales en datos que no son necesariamente experimentales (observacionales la mayoría de veces). Con ello, vamos a poder responder una serie de preguntas económicas que organizan una investigación. Podemos resumir estas en 4 preguntas que nos permitirán abordar efectos causales en la investigación científica de la economía:\n\n¿Cuál es la relación causal de interés? - Relación causal permite predecir consecuencias\n¿Cuál es el experimento ideal para capturar el efecto causal? - No siempre vamos a tener que realizar un experimento, pero si tenerlo como ideal. Un diseño experimental suele ser costoso, difícil y muchas veces anti ético.\n¿Cuál es la estrategia de identificación? - Uso de datos observacionales para aproximarse a un experimento\n¿Cuál es el modo de inferencia estadística? - Población bajo estudio y construcción de errores estándar"
  },
  {
    "objectID": "sesiones/01-causalidad.html#validez-del-análisis-empírico",
    "href": "sesiones/01-causalidad.html#validez-del-análisis-empírico",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "1.2 Validez del análisis empírico",
    "text": "1.2 Validez del análisis empírico\nPartamos con las siguientes preguntas:\n\n¿Qué hace que un análisis empírico sea fiable?\n¿Cuándo proporciona la regresión múltiple un estimador útil del efecto causal?\n\nEstas preguntas las vamos a responder en dos claves en la sesión: estudiando trabajos empíricos, papers o análisis estadísticos y estableciendo un marco para evaluar estudios estadísticos en general basado en dos conceptos: validez interna y validez externa.\n\n1.2.1 Validez Interna y Externa\nPara evaluar cualquier estudio empírico, analizamos dos dimensiones:\n\nValidez Interna: Un estudio es válido internamente si sus ingerencias estadísticas acerca de los efectos causales son válidad para la población y el escenario estudiados.\nValidez Externa: Un estudio es válido externamente si sus ingerencias pueden generalizarse a otraas poblaciones y escenarios.\n\nCuando hablamos de población estudiada vs la población de interés, podemos señalar la siguiente diferencia:\n\nPoblación estudiada: individuos que componen la muestra.\nPoblación de interés: individuos a los que se le aplicará inferencia causal, la población a la que se busca generalizar los resultados de la muestra.\n\nEjemplos: vacunas en ratones (muestra) vs vacunas en humanos (población); reducir tamaño de clases en educación primaria vs secundaria (población); incentivos a la participación labboral de hombres vs mujeres; comportamiento en monopoly vs vida real (escenario); crecimiento de hortalizas en invernadero vs campo abierto (escenario).\n\n\n\n1.2.1.1 Amenazas a la validez externa\nEstas surgen a partir de las diferencias entre la población y el escenario estudiado y la población y el escenario de interés. Es decir, si la población estudiada y la de interés difieren en que la población estudiada elegida es distinta a la población interés, entonces el efecto causal estimado podría no ser el mismo. Esto ocurre por ejemplo con los ratones y los humanos. A su vez, si hay diferentes escenarios en la muestra y la población de interés, por ejemplo, en el entorno institucional, legal, físico, aún cuando la población estudiada coincida con la de interés, entonces el efecto causal podría no ser el mismo.\nAsí, mientras más ceercanos la población y el escenario del estudio con la población y escenario de interés, más fuertes serán las razones para la validez externa. Ahora bien, cuando hay amenezas, también hay soluciones: diseñar un estudio externamente válido; comparar resultados de estudios anteriores en diferentes poblaciones y escenarios (meta-análisis); etc.\n\n\n1.2.1.2 Amenazas a la validez interna\nLa validez interna de los análisis empírico (por ejemplo en regresiones múltiples) son internamente válidos si:\n\nEl modelo está bien especificado\nLos estimadores son insesgados y consistentes\nLos errores estándar proporcionan intervalos de confianza con un nivel de confianza deseado\n\nPero hay amenazas si:\n\nProblemas de especficación del modelo\nOmisión de variables relevantes\nCausalidad reversa (simultaneidad)\nDatos faltantes y sesgo de selección\nError de medición\n\n\n\n\n1.2.2 Endogeneidad\nLa endogeneidad (y su opuesto: la exogeneidad) de una(s) variable(s) es un tema fundamental para la econometría. Esta ocurre cuando \\(\\mbox{cov}(X, u) \\neq 0\\). También muchas veces en modelos de regresión vamos a decir que hay exogeneidad cuando hay correlación entre una variable explicativa y el término de error, i.e., \\(\\mbox{cor}(X, u) \\neq 0\\). Esta puede surgir por error de medición, omisión de variables relevantes, simulteaneidad, entre otras. Un ejemplo donde se podría presentar esto es el ejemplo clásico es la Ecuación de Mincer para el retorno a la educación: \\[ \\ln y_i = \\beta_0 + \\beta_1 S_i + \\gamma' X_i + u_i \\] donde \\(y_i\\) son ingresos laborales (con logaritmo aplicado), \\(S_i\\) es años de educación, \\(X_i\\) es un vector de variables de control. El parámetro de interés es \\(\\beta_1\\) que se puede interpretar como la tasa de retorno a la educación. En la Ecuación de Mincer, podríamos tener problemas de estimación por endogeneidad por:\n\nSesgo por variable omitida: “habilidad”.\n\nEstudiantes con más habilidades les va mejor en la universidad y además tienen mayores ingresos\nLas habilidades sin multidimensionales, difíciles de medir, y no suele haber información disponible en la mayoría de las fuentes de datos comúnmente utilizadas.\n\nSesgo de selección\n\nIngresos son observables para aquellos que se encuentran trabajando\nLas personas que eligen hacer más años de educación probablemente son las que tienen más para ganar (mayor retorno esperado)\n\nError de medición\n\nLa escolaridad está medida con errores: i) es difícil es determinar los años de escolaridad (sobre todo por las trayectorias académicas divergentes); ii) gran varianza en la calidad de la educación (números de años es una medida imperfecta, si se toma la escolaridad ajustada por calidad).\n\n\nOtro ejemplo podría ser la medición de la relación oferta y demanda. Por ejemplo, en un modelo de regresión: los precios son endógenos. En regresiones de precios sobre cantidades, los resultados pueden deberse tanto a cambios en la demanda como en la oferta:\n\n\n\n\n\nProblema de identificación: Oferta y Demanda"
  },
  {
    "objectID": "sesiones/01-causalidad.html#el-problema-fundamental-de-la-inferencia-causal",
    "href": "sesiones/01-causalidad.html#el-problema-fundamental-de-la-inferencia-causal",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "1.3 El Problema Fundamental de la Inferencia Causal",
    "text": "1.3 El Problema Fundamental de la Inferencia Causal\nAquí tenemos que volver a lo que adelantamos en la formalización del selection bias. La mayoría de las veces que debemos conformarnos con datos obtenidos en contextos no experimentales (observacionales). Según Holland (1986), el problema fundamental de la inferencia causal es que: si \\(X\\) es la causa e \\(Y\\) el resultados, una vez que cambia \\(X\\) y, por lo tanto, cambia \\(Y\\), no es posible observar qué hubiese ocurrido con \\(Y\\) en ausencia del cambio. Es decir, no es posible visualizar empíricamente este escenario por su carácter contrafactual.\nEntonces, tomemos lo que dijimos antes: supongamos que cada individuo de la población objetivo puede ser potencialmente tratado. Diseñemos, pues, una variable dummy, \\(D\\), que toma el valor 1 si se recibe tratamiento, 0 si no. Es decir, \\[\ny_i =\n\\begin{cases}\n  y_{1i}, & \\quad \\text{si } D_i =1\\\\\n  y_{0i}, & \\quad \\text{si } D_i =0\\\\\n\\end{cases}\n\\] lo cual, como ya vimos, podemos escribir la variable resultado en función de los resultados potenciales: \\[\ny_i = y_{0i}+(y_{1i}-y_{0i})D_i\n\\] donde \\(y_{1i}\\) es el resultado de la persona \\(i\\) si recibe tratamiento, \\(y_{0i}\\) es su resultado si no lo recibe. Entonces, también como ya mencionamos, el efecto causal del tratamiento para el inidividuo \\(y_i\\) será \\[\n\\tau_i = y_{1i}- y_{0i}\n\\] Ahora bien, ahora surge un problema central, ya mencionado por Holland (1986): nunca observamos ambos resultados para un mismo individuo. Entonces, lo que debemos preguntarnos es ¿qué obtenemos si comparamos los resultados promedios de individuos tratados y no tratados? Lo que se obtiene es lo siguiente:\nNo tratados: \\[E[y_i\\mid D_i =0]= \\color{red}{E[y_{0i} \\mid D_i = 0]} \\] Tratados: \\[\n\\begin{aligned}\nE[y_i \\mid D_i = 1] &= E[y_{1i} \\mid D_i = 1] \\\\\n&= \\color{red}{E[y_{0i} \\mid D_i = 1]}\n   + \\color{red}{E[y_{1i} - y_{0i} \\mid D_i = 1]} \\\\\n&= \\color{red}{E[y_{0i} \\mid D_i = 1]}\n   + \\color{red}{E[\\tau_i \\mid D_i = 1]}\n\\end{aligned}\n  \\] Entonces, tomando la diferencia entre ambos grupos, \\(E[y_i \\mid D_i = 1]- E[y_i\\mid D_i =0]\\), llegamos al resultado que habíamos anunciado antes: \\[\n\\begin{aligned}\n  E[y_i \\mid D_i = 1]- E[y_i\\mid D_i =0] = \\underbrace{E[y_{1i} - y_{0i} \\mid D_i=1]}_{\\text{ATT}} + \\underbrace{E[y_{0i} \\mid D_i=1] - E[y_{0i}\\mid D_i=0]}_{\\text{Sesgo de Seleccion}}\n\\end{aligned}\n\\] Con ello, podemos observar que el sesgo proviene del hecho de que aquellos que buscan tratamiento (\\(D_i=1\\)), tienen características diferentes. Por otro lado, nos encontramos con el ATT. El Average treatment effect on the treated (ATT) es el efecto promedio del tratamiento para los individuos tratados. Si los efectos son heterogéneos en la población, este es un afecto causal diferente al efecto promedio en la población (ATE). Luego lo veremos. Pero ahora, pasemos al segundo bloque para seguir profundizando."
  },
  {
    "objectID": "sesiones/01-causalidad.html#experimentos-y-causalidad",
    "href": "sesiones/01-causalidad.html#experimentos-y-causalidad",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "2.1 Experimentos y causalidad",
    "text": "2.1 Experimentos y causalidad\nCon datos observacionales, la identificación del efecto causal es complejo, aunque no imposible. Pero conviene partir cómo se captura esto con datos experimentales. Nuevamente, esto es para seguir con el concepto de ideal experimental: lo ideal será ahcer un un experimento donde solo modificamos \\(X\\), dejando todo lo demás constante (ceteris paribus), para obser el efecto de la variación de \\(X\\) en \\(Y\\). Para algunos tipos de preguntas, pues, podemos hacer experimentos con grupos de control aleatorio: RCT, por sus cifras en inglés: Randomized Control Trials.\nRandomized Control Trials (RCT’s): la idea de los RCT’s proviene de la medicina, por ejemplo, tomando los tipos de investigaciones para medir la efectividad de un nuevo fármaco o vacuna. En este tipo de experimentos, se elige un grupo de pacientes aquejados por la enfermedad que el nuevo fármaco pretende curar. Entonces, se podría realizar lo siguiente:\n\nSe asigna al azar a cada paciente a uno de tres grupos:\n\nel fármaco nuevo\nel fármaco en uso\nun placebo (sin contenido medicinal (y sin informar cuál es cuál))\n\nSe compara la respuesta promedio de los tres grupos al tratamiento\n\nEntonces, tenemos que los pacientes no saben en qué grupo están, e idealmente los que administran los fármacos idealmente tampoco deberian saber a qué grupo pertenece cada paciente. Con ello, se podría formar un caso típico de RCT. Y, en el caso de que la respuesta de los tratados con el nuevo fármaco es significativamente mejor que la de los restantes grupos, se podría concluir que el nuevo fármaco es efectivamente mejor que el anterior.\nEn economía también se han realizado RCT’s. Entre algunos de ellos:\n\nNational Supported Work Demonstration, 1975-1979\nNegative Income Tax Experiments, 1968-1979\nRAND Health Insurance Experiment, 1971-1986\nMoving to Opportunity, 1994-2010\nTennessee STAR Experiment, 1985-1998\nPerry Preschool Program, 1960s\nProgresa/Oportunidades en Mexico, 1997-1999\nTambién hay muchos ejemplos en economía del desarrollo (Esther Duflo: Experimentos sociales para luchar contra la pobreza)"
  },
  {
    "objectID": "sesiones/01-causalidad.html#asignación-aleatoria",
    "href": "sesiones/01-causalidad.html#asignación-aleatoria",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "2.2 Asignación aleatoria",
    "text": "2.2 Asignación aleatoria\nEntendiendo la idea de los RCT’s, veamos un concepto fundamental de los diseños experimentales. Pero antes, retomemos un poco. Hasta aquí tenemos lo siguiente:\n\nUn experimento define a un grupo de tramiento y otro de control. De aquí existen dos resultados posibles:\n\n\nResultado con tratamiento \\(y_{1i}\\)\nResultado sin tratamiento \\(y_{0i}\\)\n\n\nSolo podemos observar uno de los dos resultados para \\(i\\). Para ello, definimos la asignación de tratamiento con una variable de tratamiento \\(D_i\\), que nos permite identificar: \\[\ny_i =\n\\begin{cases}\n  y_{1i}, & \\quad \\text{si } D_i =1\\\\\n  y_{0i}, & \\quad \\text{si } D_i =0\\\\\n\\end{cases}\n\\]\nEl efecto causal del tratamiento es \\[\n\\tau_i =y_{1i}-y_{0i}\n\\] pero no se puede observar directamente \\(\\tau_i\\).\nDado que no se puede observar \\(\\tau_i\\), se dfine el efecto promedio del tratamiento (ATE) como \\[\nE[\\tau_i] = E[y_{1i}-y_{0i}]\n\\] y el efecto promedio sobre los tratados (ATT) como \\[\nE[\\tau_i \\mid D_i =1] = E[y_{1i}-y_{0i}\\mid D_i =1]\n\\]\nAl tratar con el problema econométrico, recordemos qué pasaba cuando tomabamos la diferencia entre ambios grupos: \\[\nE[y_{1i} \\mid D_i = 1] - E[y_{0i} \\mid D_i =0]\n\\] que es equivalente a \\[\nE[y_{1i} \\mid D_i = 1] - E[y_{0i} \\mid D_i = 1] + E[y_{0i} \\mid D_i = 1] - E[y_{0i} \\mid D_i = 0]\n\\] donde \\(E[y_{1i} \\mid D_i = 1]- E[y_{0i} \\mid D_i = 1]\\): ATT; y \\(E[y_{0i} \\mid D_i = 1]- E[y_{0i} \\mid D_i = 0] \\neq 0\\): Sesgo de selección (SS). Entonces teníamos que \\[\nE[y_{1i} \\mid D_i = 1]-E[y_{0i} \\mid D_i = 0] = ATT+ SS\n\\] No obstante, la comparación del promedio de los grupos no nos da per se el efecto del tratamiento (de hecho, no siempre es cero). Si no que, esto lo obtendremos con la aleatorización.\n\n\n2.2.1 La Solución Experimental: Por qué funciona la Aleatorización\nComo vimos en la sección anterior, el sesgo de selección surge porque las personas se “autoseleccionan” en el tratamiento basándose en sus características (y por ende, en sus resultados potenciales). Quienes van al hospital (\\(D_i=1\\)) tienen, de base, una salud (\\(Y_{0i}\\)) peor que quienes no van. La asignación aleatoria (Random Assignment) resuelve este problema de raíz. ¿Cómo? Desvinculando el tratamiento de las características del individuo.\nEn un RCT, la asignación del tratamiento \\(D_i\\) es decidida por un mecanismo aleatorio (una moneda, una lotería, un generador de números aleatorios). Esto implica una propiedad estadística fundamental descrita por Angrist y Pischke (2008): la independencia: \\[\\{Y_{1i}, Y_{0i}\\} \\perp \\!\\!\\! \\perp D_i\\]\nEsto se lee así: los resultados potenciales son independientes del estatus de tratamiento. En palabras simples: el hecho de que seas asignado al grupo de tratamiento o al de control no tiene nada que ver con tu salud previa, tu motivación, tu inteligencia o tu nivel socioeconómico. Es puro azar. Esta independencia es la herramienta más poderosa de la econometría experimental. Nos permite afirmar que, en promedio, los individuos del grupo de control son idénticos a los del grupo de tratamiento antes de la intervención.\n\n2.2.1.1 La Derivación Formal\nEsta independencia nos permite hacer una “magia” matemática. Recordemos nuestra descomposición de la diferencia de medias observada:\n\\[\n\\underbrace{E[Y_i | D_i=1] - E[Y_i | D_i=0]}_{\\text{Diferencia Observada}} = \\underbrace{E[Y_{1i} | D_i=1] - E[Y_{0i} | D_i=1]}_{\\text{ATT}} + \\underbrace{E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]}_{\\text{Sesgo de Selección}}\n\\]\nBajo aleatorización, el término de sesgo de selección desaparece. Siguiendo a A&P (2008), la lógica es la siguiente: dado que \\(D_i\\) es independiente de \\(Y_{0i}\\), el promedio del resultado potencial “sin tratamiento” (\\(Y_{0i}\\)) es estadísticamente idéntico en ambos grupos.\n\\[E[Y_{0i} | D_i = 1] = E[Y_{0i} | D_i = 0] = E[Y_{0i}]\\]\nEsto es lo que A&Pe llaman la capacidad de “intercambiar” (swap) términos. Podemos usar el resultado observado del grupo de control (\\(E[Y_{0i} | D_i=0]\\)) como un contrafactual perfecto para el grupo de tratamiento.\n\n\n2.2.1.2 El Resultado: ATE = ATT\nSi el sesgo de selección es cero, la ecuación se simplifica dramáticamente:\n\\[\n\\begin{aligned}\nE[Y_i | D_i=1] - E[Y_i | D_i=0] &= E[Y_{1i} | D_i=1] - E[Y_{0i} | D_i=1] \\\\\n&= E[Y_{1i} - Y_{0i} | D_i=1] \\\\\n&= E[Y_{1i} - Y_{0i}]\n\\end{aligned}\n\\]\nBajo aleatorización, la diferencia de medias simple no solo recupera el Efecto Promedio en los Tratados (ATT), sino que, como la muestra es representativa y la asignación es aleatoria, este es igual al Efecto Promedio del Tratamiento (ATE) poblacional (Angrist y Pischke, 2008).\n\n\n\n\n\n\nIntuición Económica: En el ejemplo del hospital de A&P, si forzáramos a una muestra aleatoria de la población a ir al hospital (independientemente de si están enfermos o no), eliminaríamos el hecho de que “los enfermos buscan tratamiento”. Así, compararíamos la salud de un grupo promedio hospitalizado versus un grupo promedio no hospitalizado. La diferencia sería, indiscutiblemente, el efecto causal de la atención médica.\n\n\n\nEn suma, si \\(D_i\\) es asignado al azar, entonces es independiente de \\(y_i\\), tal que \\[\nE[y_{1i} \\mid D_i = 1] = E[y_{1i} \\mid D_i = 0] = E[y_{1i}] .\n\\] Luego, teníamos que el efecto del tratamiento es el siguiente: \\[\nE[y_{1i}\\mid D_i =1]-E[y_{0i}\\mid D_i =0] = ATT\n\\] por lo que ahora: \\[\nE[y_{1i}\\mid D_i =1] - E[y_{0i}\\mid D_i =1] = E[y_{1i}-y_{0i}].\n\\] Es decir, que el ATT coincide con el ATE. Además, vale la pena mencionar que el estimador de ATE se puede calcualr como diferencia de medias: \\[\n\\bar{Y}\\mid D_i = 1 - \\bar{Y}\\mid D_i = 0\n\\] Por último, una sintesis hasta aquí de lo que llevamos de manera esquemática:\n\n\n\n\n\nflowchart LR\n\n    %% Nodos principales\n    P[\"Población\"]\n    M[\"Muestra\"]\n    GT[\"Grupo tratamiento\"]\n    GC[\"Grupo control\"]\n\n    %% Nodos de texto (etiquetas en cajas)\n    T1[\"Muestreo Aleatorio&lt;br/&gt;Validez Externa\"]\n    T2[\"Asignación Aleatoria&lt;br/&gt;Validez Interna\"]\n    T3[\"Asignación Aleatoria&lt;br/&gt;Validez Interna\"]\n\n    %% Conexiones\n    P --&gt; T1 --&gt; M\n    M --&gt; T2 --&gt; GT\n    M --&gt; T3 --&gt; GC\n\n    %% Estilo de cajas principales\n    classDef main fill:#f6eeee,stroke:#666,stroke-width:1px,color:#8b0000\n    class P,M,GT,GC main\n\n    %% Estilo de cajas de texto intermedias\n    classDef label fill:#ededed,stroke:#ededed,color:#8b0000,font-size:12px\n    class T1,T2,T3 label"
  },
  {
    "objectID": "sesiones/01-causalidad.html#experimentos-aleatorizados-proyecto-star",
    "href": "sesiones/01-causalidad.html#experimentos-aleatorizados-proyecto-star",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "2.3 Experimentos aleatorizados: Proyecto STAR",
    "text": "2.3 Experimentos aleatorizados: Proyecto STAR\nAlgo que no hemos mencionado hasta ahora: para un experimento aleatorio, en general vamos a necesitar un número lo suficientemente grande de personas en cada grupo. Por ejemplo, si tenemos solo 1 personas en cada grupo, es muy probable que estas dos personas difieran en cosas distintas generando sesgo por selección. En cambio, si tenemos grupos con un \\(n\\) lo suficientemente grande e individuos elegidos al azar, entonces, aunque cada individuo sea diferente, la mayoría de las características serán similares en promedio. A esto también le llamamos en expectativa, pues calculamos el valor esperado por notación generalmente como ya vimos.\nPero, ¿cómo sabemos que el tamaño \\(n\\) influye de tal manera? Bueno, por la propiedad estadística de la Ley de los Grandes Números: el promedio muestral se acerca al promedio poblacional a medida que aumenta el tamaño de la muestra. El promedio poblacional se llama esperanza matemática, \\(E[y]\\). Entonces, \\(\\bar{y} \\to E[y]\\).\nLuego de aleatorizar, se debe chequear que los grupos de tratamiento y de control no tinene diferencias en variables observables (características y variable de resultado), previo a la intervención. Veamos cómo ocurre esto con una investigación empírica real: el Proyecto STAR (Student/Teacher Achievement Ratio), ejecutado durante los 80s en Tennessee (US), donde se redujo el tamaño de la clase de pre-escolares. La asignación aleatoria de estudiantes en 3 grupos\n\nTratamiento: 1) Clases pequeñas (13-17 alumnos).\nControl: 2) Clases regulares (22-25 alumnos) y un asistente de profesor a tiempo parcial; o 3) clases regulares con un asistente de profesor a tiempo completo.\n\nAsí, una de las primeras preguntas que hay que plantearse sobre un experimento aleatorio es “si la aleatorización ha logrado equilibrar con éxito las características de los sujetos entre los diferentes grupos de tratamiento” (Angrist y Pischke, 2008, p. 14, traducción propia). Para ello, se suele comparar resultados previos al tratamiento y/u otras covariables. Los datos de STAR, no obstante, no incluyen las puntuaciones de las pruebas previas al tratamiento, pero es posible examinar caracteristicas personales como la raza y la edad. A&P muestran la siguiente tabla, en la cual debemos verificar que la aleatorización funcionó. Las características pre-tratamiento deben ser iguales entre grupos:\n\n\n\n\n\nTabla de Balance Proyecto STAR\n\n\n\n\nEntonces, el “tratamiento” serían las clases pequeñas (Columna “Small”) y los dos controles diferenciados por clases regulares (igual de grandes que antes), pero con la diferenciación del profe a tiempo completo o parcial. Las variables relevantes en verdad son las 3 primeras: 1. Almuerzo gratis, 2. Blanco/asiático y 3. Edad en 1985. Se presentan medias, por lo que sería, por ejemplo, para 1: 47% de los alumnos recibían almuerzo gratuito en salas pequeñas, 48% en regulares y 50% en regulares con profe asistente. Como vemos, coinciden los valores en casi todas. Al rededor del 50% tiene almuerzo gratis en todas los tipos de salas (nivel socioeconómico (bajo) similar), al rededor de 2/3 son blancos o asiaticos y la edad promedio en 1985 era casi de 5 años y medio. El joint \\(p-\\)value (es un \\(F-\\)test) indica si hay diferencias significativas estadísticamente habblando. COmo vemos, ninguna \\(p&lt;0.05\\), por lo que no hay diferencias signidicativas entre los grupos de control y el tratado. Esto indica que son grupos con características similares3.\nPor lo tanto, son grupos balanceados. Además, dado que “la aleatorización elimina el sesgo de selección, la diferencia en los resultados entre los grupos de tratamiento refleja el efecto causal medio del tamaño de la clase (en relación con las clases normales con un asistente a tiempo parcial)” (Angrist y Pischke, 2008, p. 15, traducción propia). En la práctica, la diferencia en las medias entre los grupos de tratamiento y control puede obtenerse a partir de una regresión de las puntuaciones de las pruebas sobre variables dummy para cada grupo de tratamiento, un punto que se trata aquí con una tabla, pero que después profundizaremos con más detenimiento. En cualquier caso, la tabla es la siguiente (solo para adelantar, luego la analizamos bien):\n\n\n\n\n\nEstimaciones experimentales del efecto de la asignación del tamaño de clase en los puntajes de los exámenes"
  },
  {
    "objectID": "sesiones/01-causalidad.html#ventajas-y-limitaciones-de-los-experimentos-aleatorizados",
    "href": "sesiones/01-causalidad.html#ventajas-y-limitaciones-de-los-experimentos-aleatorizados",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "2.4 Ventajas y limitaciones de los experimentos aleatorizados",
    "text": "2.4 Ventajas y limitaciones de los experimentos aleatorizados\nAntes de pasar al bloque de regresión e inferencia, que es donde retomaremos la tabla anterior, conviene decir algunas cosas. Si bien los RCTs son considerados el Gold Standard para la identificación causal debido a su capacidad para asegurar la validez interna, no están exentos de desafíos prácticos y teóricos. No basta con aleatorizar; el investigador debe ser consciente de las barreras que pueden comprometer tanto la integridad del experimento como su utilidad para el diseño de políticas públicas.\n\n2.4.1 El poder de la aleatorización (Ventajas)\nLa principal fortaleza de un RCT es que la asignación exógena del tratamiento permite “limpiar” la estimación de ruidos estadísticos que suelen invalidar los estudios observacionales:\n\nEliminación del Sesgo de Selección: eomo demostramos formalmente, al asignar aleatoriamente garantizamos que \\(cov(D_i, \\eta_i) = 0\\). Esto elimina la correlación sistemática entre el tratamiento y las características observadas (y, crucialmente, las no observadas) de los participantes.\nAusencia de Causalidad Inversa: dado que es el investigador quien impone el tratamiento exógenamente, por definición, eliminamos la posibilidad de que sea la variable resultado \\(Y\\) la que cause \\(D\\).\nPermiten variar distintos parámetros, en lugar de enfrentar el efecto de múltiples cambios de política que ocurren simultáneamente. Y eso también nos permite probar tratamientos que no serían factibles en la realidad.\nTransparencia: Los resultados de un experimento bien ejecutado son fáciles de comunicar, ya que se basan en una comparación directa de promedios entre grupos, sin necesidad de modelos estructurales complejos.\n\n\n\n2.4.2 Desafíos y Amenazas (Limitaciones)\nNo obstante, llevar un experimento al “mundo real” presenta limitaciones severas que clasificamos en tres dimensiones:\n\n2.4.2.1 Restricciones estructurales y éticas\nEl costo monetario y político de un RCT es masivo. Además del financiamiento, existen preguntas económicas que simplemente no pueden responderse mediante experimentos por razones éticas (ej: ¿cuál es el efecto de la contaminación en la salud infantil?) o técnicas. Esto último, es importante, porque se podrán tener todos los recursos del mundo, pero a veces son inviables porque las personas tratadas no quieren exponerse a un experimento aleatorio de tal naturaleza.\n\n\n2.4.2.2 Amenazas a la Validez Interna\nIncluso con un diseño robusto, la ejecución puede fallar reintroduciendo sesgos:\n\nProblemas de implementación: los problemas de implementación pueden ocurrir en un RCT. Por ejemplo, puede existir una mala práctica en la asignación aleatoria, generando que \\(\\mbox{cov}(D_i, u_i) \\neq 0\\). A su vez, pueden ocurrir incumplimientos de protocolos: el grupo de tratamiento no recibe todo el tratamiento y el grupo de control recibe parte del tratamiento (partial compliance).\nSesgo de Deserción (Attrition): si la pérdida de participantes no es aleatoria (ej: si los más enfermos en el grupo de control abandonan el estudio), la comparación final estará sesgada. También puede ocurrir que no aleatoriamente parte de la muestra no responda entrevistas o al tratamiento.\nSesgo de desempeño: los participantes pueden cambiar su conducta por saberse observados (Efecto Hawthorne) o el grupo de control puede buscar activamente sustitutos al tratamiento (Sesgo de sustitución), sesgando el efecto hacia cero4.\nSesgo de sustitución: el grupo de control puede buscar tratamientos sustitutos porque se les negó el tratamiento. Es por eso que se utilizan placebos. Mientras la muestra esté menos consciente de si se le asignó o no el tratamiento, mejor.\n\n\n\n2.4.2.3 Amenazas a la Validez Externa\nUn experimento puede ser válido para su muestra, pero su capacidad de generalización es limitada si el efecto del tratamiento difiere entre contextos geográficos o periodos de tiempo. Además, resultados a pequeña escala pueden no mantenerse al masificarse debido a efectos de equilibrio general.\n\n\n\nTipología de Efectos del Tratamiento\nCuando los efectos del tratamiento son heterogéneos, debemos ser precisos sobre qué estamos midiendo exactamente:\n\nEfectos del Tratamiento: Definiciones Clave\n\nATE (Average Treatment Effect): Es el efecto promedio esperado si asignáramos a un individuo aleatorio de la población al tratamiento. \\[ATE = E[Y_{1i} - Y_{0i}]\\]\nATT (Average Treatment Effect on the Treated): Es el efecto promedio para quienes efectivamente recibieron el tratamiento. \\[ATT = E[Y_{1i} - Y_{0i} \\mid D_i = 1]\\]\n\\(ATE(x)\\) (Efecto Condicional): El efecto promedio para un subgrupo específico con características \\(x\\). \\[E[Y_{1i} - Y_{0i} \\mid X_i = x]\\]\n\n\nEn un experimento con asignación aleatoria perfecta, el tratamiento es independiente de los resultados potenciales, lo que implica que el grupo tratado es estadísticamente idéntico al grupo de control antes de la intervención. En este escenario ideal: \\[ATE = ATT\\]"
  },
  {
    "objectID": "sesiones/01-causalidad.html#el-problema-del-cumplimiento-take-up",
    "href": "sesiones/01-causalidad.html#el-problema-del-cumplimiento-take-up",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "2.5 El problema del cumplimiento (Take-up)",
    "text": "2.5 El problema del cumplimiento (Take-up)\nEn la práctica, la asignación al tratamiento no siempre equivale a la recepción del mismo (Take-up). Si existe una proporción de individuos que no toma el tratamiento asignado, estamos bajo “imperfect compliance”.\nPuesto que la decisión de tomar el tratamiento (\\(T_i\\)) ya no es aleatoria (depende de la voluntad o características del individuo), comparar a quienes se trataron contra quienes no reintroduce el sesgo de selección. Por esta razón, en estos contextos se estima el ITT (Intention-to-Treat), que mide el efecto de haber sido asignado al tratamiento, independientemente de la adopción final.\n\n\n\n\n\n\n\n\nResumen de Estimadores de Impacto\n\n\nConcepto\nDefinicion\nUso.Principal\n\n\n\n\nATE\nEfecto promedio poblacional\nInferencia general\n\n\nATT\nEfecto promedio en quienes se tratan\nEvaluacion de impacto directo\n\n\nITT\nEfecto de ser asignado al tratamiento\nPolitica publica con adopcion parcial"
  },
  {
    "objectID": "sesiones/01-causalidad.html#análisis-de-regresión-en-experimentos",
    "href": "sesiones/01-causalidad.html#análisis-de-regresión-en-experimentos",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "3.1 Análisis de regresión en experimentos",
    "text": "3.1 Análisis de regresión en experimentos\n¿Para qué vamos a usar regresiones en experimentos aleatorizados? En primer lugar, el estimador \\(\\hat \\tau\\) podríamos estimarlo con una regresión simple. ¿Cuál sería esa regresión? Tendríamos que regresar nuestra variable de resultados, \\(y_i\\), es decir Percentile score in kindergarten, contra una dummy, \\(D_i\\), que indica si se está o no en una clase pequeña, esto es, si recibió o no tratamiento. Entonces, si suponemos que ele fecto de un tratamiento es igual para todos los individuos, se tiene que \\[\ny_{1i}-y_{0i} = \\tau\n\\] Luego, con efecto constante, re escribimos esto como \\[\n\\begin{aligned}\n  y_i &= y_{0i}+ (y_{1i}- y_{0i})D_i\\\\\n  &=y_{0i} + \\tau D_i + E[y_{0i}]-E[y_{0i}]\\\\\n  &= E[y_{0i}]+\\tau D_i + (y_{0i}- E[y_{0i}])\\\\\n  &= \\alpha + \\tau D_i + \\eta_i\n\\end{aligned}\n\\] Por lo tanto, nuestra regresión a estimar sería \\[\ny_i = \\alpha + \\tau D_i + \\eta_i\n\\] donde, si se estima, entonces \\(\\hat\\alpha\\) es el intercepto: cuando el tratamiento es cero. Y el \\(\\hat \\tau\\) sería la diferencia entre los tratados y los no tratados. Lo que tenemos, por tanto, es que el valor esperado para tratados y no tratados sería: \\[\n\\begin{aligned}\n  E[y_i \\mid  D_i = 1] &= \\alpha + \\tau + E[\\eta_i | D_i = 1]\\\\\n  E[y_i \\mid  D_i = 0] &= \\alpha + E[\\eta_i | D_i = 0]\n\\end{aligned}\n\\] Entonces, \\[\n  E[y_i \\mid D_i =1]- E[y_i \\mid D_i =0] =\\tau + E[\\eta_i \\mid D_i =1]- E[\\eta_i \\mid D_i =0]\n\\] Con asignación aleatoria, basta realizar una regresión de \\(y_i\\) sobre \\(D_i\\): \\[\nE[y_i\\mid D_i = 1]- E[y_i \\mid D_i = 0] = \\tau\n\\] Nos da exactamente lo mismo. No obstante, el uso de regresores adicionales puede contribuir a generar estimadores más precisos en dos situaciones:\n\nCuando el diseño es aleatorio condicional a otra variable (Proyecto STAR: aleatorización dentro de escueal y no entre escuelas, por que se introduce un efecto fijo por escuela)\nRegresores disminuyen el error estándar poque tienen poder explicativo sobre \\(y_i\\), aún cuando las pruebas de balance indiquen diferencias no significativas.\n\nEs más, si vemos la tabla 2.2.2. que dejamos pendiente, que es justamente un modelo de regresión del experimento, tenemos los mismos resultados (aunque agregaron más controles después):\n\n\n\n\n\nEstimaciones experimentales del efecto de la asignación del tamaño de clase en los puntajes de los exámenes\n\n\n\n\nComo vemos, en la primera tabla la diferencia en la variable de resultados Percentile score in kindergarten entre el puintaje promedio de estar en una clase pequeña respecto a una regular es \\[\n\\hat \\tau = \\bar{Y}_1- \\bar{Y}_0 = 54.7-50.0 = 4.7\n\\] En el modelo de regersión, en la columna 1 donde no se han agregado controles, la diferencia es: \\[\n\\hat \\tau = 4.82-0.12 = 4.7\n\\] Esto es evidente, porque lo que indica el modelo de regresión en el \\(\\widehat{\\text{Small class}} = 4.82\\) es que estar en una clase pequeña (tratamiento) sube el puntaje promedio en 4.82 respecto de no estarlo (control). En cambio, el estimador \\(\\widehat{\\text{Regular}} = 0.12\\) indica que aumenta en promedio solo 0.12. La diferencia es el efecto causal, que es lo mismo que calcular la diferencia entre las medias de Percentile score in kindergarten si se aplicó o no el tratamiento.\nEntonces, en efecto, no hay diferencia entre restar las medias en un RCT, y aplicar un modelo de regresión simple al RCT. Pero, como ya vimos, no significa que sea inútil aplicar el modelo de regresión al RCT, pues nos sirve para ir agregando controles de manera más efectiva, además de para ponderar valores si el experimento está desbalanceado.\nLo que tenemos es, pues, todo lo siguiente. Dado que ya demostramos que si el efecto es constante para todos los individuos, entonces podemos escribir \\[\n  y_i = \\alpha + \\tau D_i +  \\eta_i\n\\] y que, con \\(D_i\\) aleatorio, entonces se cumple \\(E[\\eta_i \\mid D_i ] = 0\\), luego se cumplen los supuestos de MCO y obtenemos un estimador insesgado de \\(ATE(\\tau)\\). Y, entonces, tenemos que \\[\n\\hat \\tau = \\widehat{ATE} \\quad \\text{ y } \\quad E[\\hat\\tau] = ATE\n\\] De tal modo, no es necesario incluir controles para obtener un estimador ATE insesgado, pero podemos incluir controles para disminuir la varainaza del error, para ponderar mejor valores, etc. Respecto a disminuir la varianza, que nos servirá incluido cuando el experimento esté bien balanceado (ergo, siempre será útil aplicar un modelo de regresión), supongamos que agregamos \\(X_i\\), tal que \\[\n\\begin{aligned}\n  y_i &= \\alpha + \\tau D_i + \\beta X_i - \\beta X_i + \\eta_i\\\\\n  y_i &= \\alpha + \\tau D_i + \\beta X_i+  \\nu_i\n\\end{aligned}\n\\] donde \\(\\nu_i = \\eta_i - \\beta X_i\\) y, por tanto, si \\(\\beta \\neq 0\\), entonces la varianza del término de error disminuye. En ello reside la utilidad de realizar un análisis de regresión a un RCT incluso cuando el experimento está bien balanceado. En el fondo, siempre será útil, a pesar de que con una diferencia de medias ya estaremos obteniendo, y rigurosamente, el efecto causal de nuestro tratamiento.\nOtra cuestión útil, además de la reducción de la varianza del término de error, es que añadir controles también evita posibles sesgos si el tratamiento depende de otra variable. Por ejemplo, supongamos que \\(X_i\\) depende del tratamiento \\(D_i\\). La ecuación a estimar, por tanto, es \\[\ny_i = \\alpha + \\tau D_i + \\beta X_i + u_i\n\\] Supongamos que \\(y_i\\) es salarios, \\(D_i\\) si se recibe capacitación y \\(X_i\\) si se consigue empleo después de la capaciatación. Entonces, al agregar \\(\\beta X_i\\), se estima el impacto de haber recibido la capacitación, el tratamiento, controlando por haber obtenido un empleo. Entonces, no solo reduce la varianza del término de error, sino que en el fondo mejora la específicación de nuestro modelo muchas veces el hecho de agregar variables de control.\nMuchas veces también los controles nos sirven para chequear la calidad de la aleatorización. Así, se puede hacer una prueba de balance con test de media, o bien, correr la siguiente regresión: \\[\n  D_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_m X_{mi} + \\varepsilon_i\n\\] y aplicar un Test F: \\(H_0 : \\beta_1 =  \\beta_2 = \\ldots = \\beta_m =0\\). Ello nos indicaría si las variables de control no están relacionadas con la asignación del tratamiento."
  },
  {
    "objectID": "sesiones/01-causalidad.html#asignación-aleatoria-condicional",
    "href": "sesiones/01-causalidad.html#asignación-aleatoria-condicional",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "3.2 Asignación aleatoria condicional",
    "text": "3.2 Asignación aleatoria condicional\nEn un experimento aleatorizado, la asignación al tratamiento es independiente de los resultados potenciales y es una función conocidas de los covariables. Hay tres formas principales:\n\nAsignación completamente aleatoria\nAleatorización estratificada (aleatorización dentro de un número finito de estratos)\nAleatorización por conglomerados (aleatorización a nivel de clusters)\n\nEl siguiente esquema resume la diferencia entre la aleatorización estratificada a la por conglomerados:\n\n\n\n\n\nAleatorización estratificada vs por conglometerados (clustering)\n\n\n\n\nEn la práctica, la aleatorización rara vez es “simple” o completamente al azar sobre toda la población. A menudo, el investigador posee información previa sobre los sujetos o enfrenta restricciones logísticas que lo obligan a utilizar un mecanismo de asignación aleatoria condicional. En este diseño, la probabilidad de recibir el tratamiento es una función conocida de ciertas covariables observadas.\nComo se observa en la @stratified-vs-clusters, la arquitectura del muestreo y la asignación cambia drásticamente según cómo agrupemos a las unidades.\n\n3.2.1 Aleatorización Estratificada (Stratified Randomization)\nEste método consiste en dividir a la población en \\(G\\) estratos definidos por variables exógenas (como género, edad o nivel socioeconómico) y realizar una aleatorización independiente dentro de cada estrato.\n\nLógica: Buscamos asegurar que grupos pequeños pero importantes estén representados proporcionalmente tanto en el grupo de tratamiento como en el de control.\nVentaja Técnica: Mejora la eficiencia estadística al evitar “vectores de asignación no informativos” (por ejemplo, casos accidentales donde todos los hombres terminen en el grupo de control y todas las mujeres en el de tratamiento).\nEjemplo en STAR: La aleatorización se realizó dentro de cada escuela. Esto garantiza que las características específicas de una escuela (infraestructura, calidad docente promedio) no sesguen la comparación entre clases pequeñas y grandes.\n\n\n\n3.2.2 Aleatorización por Conglomerados (Cluster Randomization)\nA diferencia de la anterior, aquí la unidad de aleatorización no es el individuo, sino un grupo pre-existente o “cluster”.\n\nLógica: Todos los individuos pertenecientes a un mismo cluster (ej: una sala de clases, una aldea o una manzana) reciben el mismo estatus de tratamiento.\nMotivación: Se suele utilizar por razones logísticas o para minimizar spillovers (interferencias) entre vecinos que harían inviable tratar a unos y a otros no dentro de un mismo espacio.\nEjemplo en STAR: Si bien la asignación fue dentro de escuelas, cada sala de clase constituye un cluster. Esto tiene implicancias críticas para la inferencia: los errores estándar deben ajustarse (closterizarse), ya que los resultados de los alumnos dentro de una misma sala están correlacionados entre sí.\n\n\nDiferencia Fundamental: Representatividad vs. Unidad de Implementación\nMientras que la estratificación busca asegurar que la muestra sea un “espejo” de la diversidad poblacional (tomando sujetos de todos los colores en la imagen), el clustering selecciona grupos completos (bloques de color), facilitando la implementación pero sacrificando, en ocasiones, poder estadístico por la correlación intracluster.\n\n\n\n\n\n\n\n\n\nComparación de Diseños Condicionales\n\n\nDimension\nEstratificada\nConglomerados\n\n\n\n\nUnidad de asignación\nIndividuo (dentro del grupo)\nGrupo o Cluster completo\n\n\nObjetivo principal\nEquilibrio y representatividad\nViabilidad logística / Spillovers\n\n\nEfecto en precisión\nAumenta la precisión (reduce SE)\nSuele disminuir la precisión\n\n\nInferencia\nModelar con Efectos Fijos\nAjustar errores por cluster"
  },
  {
    "objectID": "sesiones/01-causalidad.html#sutva-stable-unit-treatment-value-assumption",
    "href": "sesiones/01-causalidad.html#sutva-stable-unit-treatment-value-assumption",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "3.3 SUTVA (Stable Unit Treatment Value Assumption)",
    "text": "3.3 SUTVA (Stable Unit Treatment Value Assumption)\nAhora pasamos directamente a tratar este supuesto, el Supuesto de no interferencia entre unidades (SUTVA, por sus cifras en inglés: Stable Unit Treatment Value Assumption). Este supuesto también es necesario para que el experimento tenga validez interna suficiente para que el estimador del efecto causal sea un estimador insesgado del efecto del tratamiento. Además, este supuesto luego lo veremos en otras técnicas econométricas de estimación que no son experimentales.\n\nSupuesto SUTVA\nLo central de este supuesto es que el valor de la variable de resultados, para la unidad \\(i\\) bajo el tratamiento \\(t\\) será el mismo sin importar qué tratamientos reciban otras unidades. Esto es, los tratamientos que recibe una unidad no afectan a los resultados de otra. Entonces, el tratamiento que recibe un individuo/unidad \\(i\\) no afecta en otro individuo/unidad \\(j\\), lo que está implícito en nuestra notación de resultados potenciales: \\[\ny_i =\n\\begin{cases}\n  y_{1i}, & \\quad \\text{si } D_i =1\\\\\n  y_{0i}, & \\quad \\text{si } D_i =0\\\\\n\\end{cases}\n\\] donde para que \\(y_{\\cdot i}\\) tome el valor \\(y_{1i}\\) o \\(y_{0i}\\) depende exclusivamente del tratamiento que recibe \\(i\\)\n\nAhora bien, ¿cuáles son las posibles violaciones a SUTVA?\nMIN 32 COMIENZA - BLoque 2 Econometría sesión 01\nAsumimos que no hay interferencia entre unidades: el tratamiento de \\(i\\) no afecta a \\(j\\).\n\nViolaciones: Efectos pares (spillovers), efectos de equilibrio general."
  },
  {
    "objectID": "sesiones/01-causalidad.html#pruebas-de-hipótesis",
    "href": "sesiones/01-causalidad.html#pruebas-de-hipótesis",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "3.4 Pruebas de Hipótesis",
    "text": "3.4 Pruebas de Hipótesis\n\nMuestras grandes: Test-t asintótico estándar.\nMuestras pequeñas: Test Exacto de Fisher (permutaciones)."
  },
  {
    "objectID": "sesiones/01-causalidad.html#footnotes",
    "href": "sesiones/01-causalidad.html#footnotes",
    "title": "Sesión 1: Métodos de Evaluación Causal y RCT",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEsto se mide con la pregunta que realiza la Encuesta Nacinoal de Salud (NHIS): “Would you say your health in general is excellent, very good, good, fair, poor?” donde 1 es “excellent health” y 5 es “poor health”↩︎\nOjo, aquí la escala es otra y está invertida. Primero no es de 1 a 5, sino de 1 a 7. Y aquí 1 es el peor puntaje y 7 el mejor. A diferencia que en la NHIS que 1 era el mejor puntaje y 5 el peor↩︎\nLa atrición son los casos perdidos porque se cambiaron de colegio o cualquier otro motivo↩︎\nEn mediciana, es más común realizar experimentos doble ciego para sortear esta dificultad↩︎"
  }
]