---
title: "Sesión 1: Métodos de Evaluación Causal y RCT"
subtitle: "Resultados Potenciales, Sesgo de Selección y Experimentos"
date: "2025-12-06"
author: "Fran Sofía Núñez"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: show
editor: visual
---

```{r setup}
#| include: false
#| warning: false
#| message: false

# Carga de librerías para manipulación y tablas
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, kableExtra, knitr, gt) 
```

# Introducción [EN CONSTRUCCIÓN] {-}

Esta sesión introduce el problema fundamental de la inferencia causal y establece el marco teórico de los **Resultados Potenciales (Rubin Causal Model)**. Se parte discutiendo por qué la correlación no implica causalidad, sobre el sesgo de selección y cómo los experimentos aleatorios (RCT) resuelven el problema del sesgo de selección.

# Bloque 1: Causalidad y Validez del análisis empírico

Hay muchas decisiones en economía, política, negocios, etc., que implican la comprensión correcta de la relación entre las variables implicadas. Por ejemplo, muchas veces vamos a querer testear hipótesis: ¿Existe la discriminación racial en la asignación de créditos hipotecarios? ¿En la decisión de usar la herramienta de la prisión preventiva? ¿Son iguales los salarios entre hombres y mujeres con el mismo nivel de educación y experiencia laboral? Por otro lado, también muchas veces vamos a querer cuantificar efectos (relación causal): ¿cuánto aumenta el desempeño académico de los estudiantes al reducir el tamaño de la clase? ¿Cuál es el efecto del aumento del salario mínimo en el desempleo?

Todas estas respuestas requieren una respuesta numérica y una medida de precisión que acompañe dicha respuesta, para saber el grado de error conocido. No obstante, también requiere la comprensión correcta del *tipo* de relación que une a las variables, i.e., distinguir la naturaleza de la relación entre $X$ e $Y$. 

En líneas generales, o al menos para este curso, nos va interesar la relaciones *causales* entre variables. Es decir, una relación que establezca la naturaleza del vínculo de nuestras variables tal que: 
$$
X \implies Y
$$
Para ello, es muy importante distinguir entre *relaciones causales* y *correlaciones*. Sobre todo, porque, **observacionalmente** las relaciones de correllación *pueden verse* iguales a las de causalidad. No obstante, **correlación no implica causalidad**

## Causalidad vs. Correlación

Como ya vimos, muchas relaciones entre variables pueden confundirse, sobre todo las correlaciones con las relaciones causales. Una forma típica es lo que se conoce como **correlación espúrea**. El caracter espurio de una correlación está dado por la alta asociación (o generalmente por la alta) entre variables y que, en virtud de ella, se interprete una relación de necesidad, o peor, de causalidad. 

Un ejemplo clásico de correlación espuria:

::: {.callout-note appearance="simple"}
**Ejemplo: Nicolas Cage y Ahogamientos**
Existe una correlación del 66% entre las películas de Nicolas Cage y la gente que se ahoga en piscinas. No obstante, sabemos que Nicolás Cage y sus películas no causan que más personas se ahoguen. Esto ilustra que $Corr(X,Y) \neq 0$ no implica causalidad, por más fuerte que sea el grado de asociación.
:::

```{r img-spurious}
#| echo: false
#| fig-cap: "Correlación espuria"
#| out-width: "80%"

knitr::include_graphics("images/spurious.png", error = FALSE)
```

Confundir una correlación (y peor aún: una espúrea) con una relación causal, puede llevar a errores graves. Por ejemplo, en *Mostly Harmless Econometrics* ([Angrist y Pischke, 2008](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf)) se muestra cómo hay una relación entre ir (o no) al hospital y el grado de "salud subjetiva"^[Esto se mide con la pregunta que realiza la Encuesta Nacinoal de Salud (NHIS): "Would you say your health in general is excellent, very good, good, fair, poor?" donde 1 es "excellent health" y 5 es "poor health"] reportado. Los datos son los siguientes: 

```{r tablas-seleccion-usa}
#| echo: false
#| warning: false

# --- TABLA 1: DATOS USA ---
data.frame(
  Grupo = c("Hospital", "No Hospital"),
  N = c("7,774", "90,049"),
  Media_Salud = c(2.79, 2.07),
  Error_Std = c(0.014, 0.003)
) |> 
  gt() |> 
  tab_header(
    title = md("**Tabla 1:** Comparación de medias en EE.UU. (NHIS)")
  ) |> 
  # Renombramos columnas para que se vean bonitas
  cols_label(
    Grupo = "Grupo",
    N = "N",
    Media_Salud = "Salud Promedio (1=Excelente, 5=Muy Mal)",
    Error_Std = "Error Est."
  ) |> 
  # Creamos el encabezado agrupado (el header rojo de antes)
  tab_spanner(
    label = "Resultados de Salud",
    columns = c(Media_Salud, Error_Std)
  ) |> 
  # Añadimos la nota al pie (se ajustará automáticamente al ancho total)
  tab_source_note(
    source_note = "Fuente: Angrist & Pischke (2008). Diferencia de medias: 0.71 (t=58.9)."
  ) |> 
  # Estilo visual (Ancho 100%, alineación izq, filas rayadas)
  tab_options(
    heading.background.color = "#69000C",
    column_labels.background.color = "#69000C",
    table.border.top.color = "#69000C",
    table.border.bottom.color = "#69000C",
    source_notes.font.size = px(12)
  )
```

Como se puede observar, la salud promedio de las personas que no asisten al hospital reportan que, en promedio, tienen un estado de salud mejor a los que asisten ($2{,}79 > 2{,}07$), pues el promedio de los que no asisten al hospital es más cercano al 1 ("Excelente salud") que los que sí asisten. Pero, ¿esto significa que *asistir al hospital* **_empeora_** *la salud*? Suena ridículo dicho así (o quizás no), pero lo cierto es que este tipo de relaciones se suelen establecer. Es más, ¿por qué suena ridiculo? ¿Qué es lo raro en que las personas que van al hospital tienen en promedio problemas de salud mas graves? En realidad, esto es así, pero eso no significa que *ir* a un hospital empeora la salud, es decir, no hay una relación causal. Pero, ¿por qué no la hay? 

El motivo de que no la haya se puede sintetizar en el siguiente concepto: **sesgo de selección**. En primer lugar, si miramos las características de cada grupo (quienes asisten o no al hospital), que son pre-existentes a ir o no al hospital y a declarar un buen o mal estado de salud, probablemente van a ser muy diferentes. Por ejemplo, aún no hemos visto si tienen diferencias de edad, el contexto socioeconómico, indicadores de salud *previos* a la atención, etc. Sin observar todo eso, es dificil afirmar que *ir* al hospital empeora la salud. En segundo lugar, algo que probablemente se considere de sentido común, es que probablemente las personas asisten al hospital lo hacen justamente porque tienen problemas de salud. En cambio, probablemente no tienen problemas de salud, y por eso no van a un hospital. Es decir, **las personas que se atienden en un hospital son distintas a aquellas que eligen no hacerlo, pues _se autoseleccionan_ en nuestro _tratamiento_**. A todo esto, le llamamos un problema de **sesgo de selección**. Por cierto, la evidencia de  [Angrist y Pischke (2008)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf) también se puede observar para Chile si vemos los datos de la Casen 2015^[Ojo, aquí la escala es otra y está invertida. Primero no es de 1 a 5, sino de 1 a 7. Y aquí 1 es el peor puntaje y 7 el mejor. A diferencia que en la NHIS que 1 era el mejor puntaje y 5 el peor]:  


```{r tablas-seleccion-chile}
#| echo: false
#| warning: false

# --- TABLA 2: DATOS CHILE ---
data.frame(
  Grupo = c("Hospital", "No Hospital"),
  N = c("4,849", "40,816"),
  Media_Salud = c(4.23, 4.93),
  Error_Std = c(0.022, 0.007)
) |> 
  gt() |> 
  tab_header(
    title = md("**Tabla 2:** Evidencia similar para Chile (CASEN 2015)")
  ) |> 
  cols_label(
    Grupo = "Grupo",
    N = "N",
    Media_Salud = "Salud Promedio (1=Muy Mal, 7=Muy Bien)",
    Error_Std = "Error Est."
  ) |> 
  tab_spanner(
    label = "Resultados de Salud",
    columns = c(Media_Salud, Error_Std)
  ) |> 
  tab_source_note(
    source_note = "Fuente: Elaboración propia con CASEN 2015. Diferencia de medias: 0.70 (t=33.1)."
  ) |> 
  tab_options(
    heading.background.color = "#69000C",
    column_labels.background.color = "#69000C",
    table.border.top.color = "#69000C",
    table.border.bottom.color = "#69000C",
    source_notes.font.size = px(12)
  )
```


### El problema de Selección (Formalización)

Hasta ahora hemos hablado intuitivamente sobre por qué comparar promedios directos nos lleva a errores. Para ser rigurosos, debemos formalizar esto utilizando el lenguaje de los **Resultados Potenciales** (*Potential Outcomes*), el bloque fundamental de la econometría moderna. Con ello, nos adelantaremos unos pasos, pero después lo retomamos de nuevo. 

Siguiendo a [Angrist y Pischke (2008)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf), imaginemos que el tratamiento (ir al hospital) es una variable binaria $D_i = \{0, 1\}$. El interés radica en saber si el resultado de salud $Y_i$ es afectado por este tratamiento.

Entonces, para cada individuo $i$, existen dos "vidas paralelas" o resultados potenciales:

* $Y_{1i}$: El estado de salud si la persona **va** al hospital ($D_i=1$).
* $Y_{0i}$: El estado de salud si la persona **no va** al hospital ($D_i=0$).

El efecto causal para un individuo sería la diferencia entre estos dos estados: $\tau_i = Y_{1i} - Y_{0i}$. El problema fundamental de la inferencia causal es que **nunca podemos observar ambos resultados simultáneamente** para la misma persona. Solo observamos lo que realmente ocurrió:

$$
Y_i = \begin{cases}
Y_{1i} & \text{si } D_i = 1 \\
Y_{0i} & \text{si } D_i = 0
\end{cases}
$$

Lo cual se puede reescribir como:
$$Y_i = Y_{0i} + (Y_{1i} - Y_{0i})D_i$$

#### Descomposición de la Diferencia Observada

Cuando ingenuamente comparamos el promedio de salud de los hospitalizados con los no hospitalizados, estamos calculando la **Diferencia de Medias Observada**. Matemáticamente, esto se descompone en dos partes muy distintas:

$$
\underbrace{E[Y_i | D_i=1] - E[Y_i | D_i=0]}_{\text{Diferencia Observada}} = \underbrace{E[Y_{1i} - Y_{0i} | D_i=1]}_{\text{ATT}} + \underbrace{E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]}_{\text{Sesgo de Selección}}
$$

1.  **El Efecto Promedio en los Tratados (ATT):** $E[Y_{1i} - Y_{0i} | D_i=1]$. Esto es lo que *queremos* medir: ¿cuánto mejoró (o empeoró) la salud de quienes fueron al hospital *gracias* a ir al hospital?
2.  **El Sesgo de Selección:** $E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]$. Esta es la parte "sucia". Es la diferencia en la salud base ($Y_{0i}$) entre quienes fueron al hospital y quienes no.

Volviendo a nuestro ejemplo: como las personas que van al hospital suelen estar más enfermas de base, su $Y_{0i}$ (salud sin tratamiento) es mucho peor que el de las personas que se quedan en casa. Esto hace que el término de **Sesgo de Selección sea negativo** y muy grande, opacando cualquier efecto positivo (ATT) que el hospital pudiera tener.

En resumen, la "Comparación Naive" mezcla el efecto causal con la autoselección de los individuos. El objetivo de la econometría (y de los RCT que veremos a continuación) es eliminar este segundo término para aislar el efecto causal verdadero.

### Sintesis pre validez del análisis empírico

Entonces, volviendo al problema de la causalidad (y la correlación). Sabiendo que el problema del sesgo de selección (*selection bias*) subyace a la dificultad de identificar el carácter causal de una relación entre variables, veremos que la relación entre variables y la naturaleza entre estas es fundamental para identificar efectos causales. Por ejemplo, para el diseño de políticas públicas, va ser distinto lo que ocurre con $Y$ si una política altera el valor de $X$ si: 

  - $X \implies Y$
  - $Z \implies Y \quad \wedge \quad Z \implies X$
  - $Y \implies X$

Esquemáticamente, la distintas relaciones entre $X,Y$, se pueden resumir así: 

```{r img-causalidad}
#| echo: false
#| fig-cap: "Relaciones de causalidad"
#| out-width: "80%"

knitr::include_graphics("images/causality_xy.png", error = FALSE)
```

En este contexto, la correlación entre $X$ e $Y$ no es muy informativa sobre el efecto causal de cambiar $X$ en $Y$. Para solucionar esto, vamos a arrancar el curso con el **ideal experimental**

En esta sesión, veremos que los datos *experimentales* son muy útiles para establecer causaldiad. A su vez, a lo largo de todo el curso, veremos como pensar en el **experimento ideal** nos puede orientar y ayudar a encontrar relaciones causales en datos que no son necesariamente experimentales (observacionales la mayoría de veces). Con ello, vamos a poder responder una serie de preguntas económicas que organizan una investigación. Podemos resumir estas en 4 preguntas que nos permitirán abordar efectos causales en la investigación científica de la economía: 

  1. ¿Cuál es la relación **causal** de interés?
    - Relación causal permite predecir consecuencias 
  
  2. ¿Cuál es el **experimento ideal** para capturar el efecto causal?
    - No siempre vamos a tener que realizar un experimento, pero si tenerlo como ideal. Un diseño experimental suele ser costoso, difícil y muchas veces anti ético.  
    
  3. ¿Cuál es la estrategia de **identificación**?
    - Uso de datos observacionales para *aproximarse* a un experimento
    
  4. ¿Cuál es el modo de **inferencia** estadística?
    - Población bajo estudio y construcción de errores estándar
  
## Validez del análisis empírico

Partamos con las siguientes preguntas: 

  - ¿Qué hace que un análisis empírico sea fiable? 
  - ¿Cuándo proporciona la regresión múltiple un estimador útil del efecto causal? 

Estas preguntas las vamos a responder en dos claves en la sesión: estudiando trabajos empíricos, papers o análisis estadísticos y estableciendo un marco para evaluar estudios estadísticos en general basado en dos conceptos: **validez interna** y **validez externa**. 

### Validez Interna y Externa

Para evaluar cualquier estudio empírico, analizamos dos dimensiones:

1.  **Validez Interna**: Un estudio es válido internamente si sus ingerencias estadísticas acerca de los efectos causales son válidad para la población y el escenario estudiados.
2.  **Validez Externa**: Un estudio es válido externamente si sus ingerencias pueden generalizarse a otraas poblaciones y escenarios.

Cuando hablamos de población estudiada *vs* la población de interés, podemos señalar la siguiente diferencia: 

  - **Población estudiada**: individuos que componen la **muestra**. 
  - **Población de interés**: individuos a los que se le aplicará inferencia causal, la población a la que se busca generalizar los resultados de la muestra. 
  
    - Ejemplos: vacunas en ratones (muestra) *vs* vacunas en humanos (población); reducir tamaño de clases en educación primaria *vs* secundaria (población); incentivos a la participación labboral de hombres *vs* mujeres; comportamiento en monopoly *vs* vida real (escenario); crecimiento de hortalizas en invernadero *vs* campo abierto (escenario). 

#### Amenazas a la validez externa

Estas surgen a partir de las diferencias entre la población y el escenario estudiado y la población y el escenario de interés. Es decir, si la población estudiada y la de interés difieren en que la población estudiada elegida es *distinta* a la población interés, entonces el efecto causal estimado podría no ser el mismo. Esto ocurre por ejemplo con los ratones y los humanos. A su vez, si hay diferentes escenarios en la muestra y la población de interés, por ejemplo, en el entorno institucional, legal, físico, aún cuando la población estudiada coincida con la de interés, entonces el efecto causal podría no ser el mismo. 

Así, mientras más ceercanos la población y el escenario del *estudio* con la población y escenario de interés, más fuertes serán las razones para la validez externa. Ahora bien, cuando hay amenezas, también hay soluciones: diseñar un estudio externamente válido; comparar resultados de estudios anteriores en diferentes poblaciones y escenarios (meta-análisis); etc. 


#### Amenazas a la validez interna

La validez interna de los análisis empírico (por ejemplo en regresiones múltiples) son internamente válidos si: 

  - El modelo está bien especificado 
  - Los estimadores son insesgados y consistentes 
  - Los errores estándar proporcionan intervalos de confianza con un nivel de confianza deseado 
  
Pero hay amenazas si: 

  1. Problemas de especficación del modelo
  2. Omisión de variables relevantes 
  3. Causalidad reversa (simultaneidad)
  4. Datos faltantes y sesgo de selección
  5. Error de medición 
  
### Endogeneidad

La endogeneidad (y su opuesto: la exogeneidad) de una(s) variable(s) es un tema fundamental para la econometría. Esta ocurre cuando $\mbox{cov}(X, u) \neq 0$. También muchas veces en modelos de regresión vamos a decir que hay exogeneidad cuando hay *correlación* entre una variable explicativa y el término de error, i.e., $\mbox{cor}(X, u) \neq 0$. Esta puede surgir por error de medición, omisión de variables relevantes, simulteaneidad, entre otras. Un ejemplo donde se podría presentar esto es el ejemplo clásico es la **Ecuación de Mincer** para el retorno a la educación:
$$ \ln y_i = \beta_0 + \beta_1 S_i + \gamma' X_i + u_i $$
donde $y_i$ son ingresos laborales (con logaritmo aplicado), $S_i$ es años de educación, $X_i$ es un vector de variables de control. El parámetro de interés es $\beta_1$ que se puede interpretar como la tasa de retorno a la educación. En la Ecuación de Mincer, podríamos tener problemas de estimación por endogeneidad por: 

  - Sesgo por variable omitida: "habilidad".
    - Estudiantes con más habilidades les va mejor en la universidad y además tienen mayores ingresos
    - Las habilidades sin multidimensionales, difíciles de medir, y no suele haber información disponible en la mayoría de las fuentes de datos comúnmente utilizadas. 
    
  - Sesgo de selección
    - Ingresos son observables para aquellos que se encuentran trabajando 
    - Las personas que eligen hacer más años de educación probablemente son las que tienen más para ganar (mayor retorno esperado)
    
  - Error de medición
    - La escolaridad está medida con errores: *i*) es difícil es determinar los años de escolaridad (sobre todo por las trayectorias académicas divergentes); *ii*) gran varianza en la calidad de la educación (números de años es una medida imperfecta, si se toma la escolaridad ajustada por calidad). 


Otro ejemplo podría ser la medición de la relación oferta y demanda. Por ejemplo, en un modelo de regresión: los precios son endógenos. En regresiones de precios sobre cantidades, los resultados pueden deberse tanto a cambios en la demanda como en la oferta: 

```{r img-supply-demand}
#| echo: false
#| fig-cap: "Problema de identificación: Oferta y Demanda"
#| out-width: "90%"

knitr::include_graphics("images/supply_demand.png", error = FALSE)
```

## El Problema Fundamental de la Inferencia Causal

Aquí tenemos que volver a lo que adelantamos en la formalización del *selection bias*. La mayoría de las veces que debemos conformarnos con datos obtenidos en contextos no experimentales (observacionales). Según [Holland (1986)](https://fitelson.org/woodward/holland.pdf), el problema fundamental de la inferencia causal es que: si $X$ es la causa e $Y$ el resultados, una vez que cambia $X$ y, por lo tanto, cambia $Y$, no es posible observar qué hubiese ocurrido con $Y$ en ausencia del cambio. Es decir, no es posible visualizar empíricamente este escenario por su carácter contrafactual.  

Entonces, tomemos lo que dijimos antes: supongamos que cada individuo de la población objetivo puede ser *potencialmente tratado*. Diseñemos, pues, una variable *dummy*, $D$, que toma el valor 1 si se recibe tratamiento, 0 si no. Es decir, 
$$
y_i = 
\begin{cases}
  y_{1i}, & \quad \text{si } D_i =1\\
  y_{0i}, & \quad \text{si } D_i =0\\
\end{cases}
$$
lo cual, como ya vimos,  podemos escribir la variable resultado en función de los resultados potenciales: 
$$
y_i = y_{0i}+(y_{1i}-y_{0i})D_i
$$
donde $y_{1i}$ es el resultado de la persona $i$ si recibe tratamiento, $y_{0i}$ es su resultado si no lo recibe. Entonces, también como ya mencionamos, el **efecto causal del tratamiento** para el inidividuo $y_i$ será
$$
\tau_i = y_{1i}- y_{0i}
$$
Ahora bien, ahora surge un problema central, ya mencionado por [Holland (1986)](https://fitelson.org/woodward/holland.pdf): nunca observamos *ambos* resultados para *un mismo* individuo. Entonces, lo que debemos preguntarnos es ¿qué obtenemos si comparamos los resultados promedios de individuos tratados y no tratados? Lo que se obtiene es lo siguiente: 

**No tratados**: 
  $$E[y_i\mid D_i =0]= \color{red}{E[y_{0i} \mid D_i = 0]} $$
**Tratados**:
  $$
\begin{aligned}
E[y_i \mid D_i = 1] &= E[y_{1i} \mid D_i = 1] \\
&= \color{red}{E[y_{0i} \mid D_i = 1]} 
   + \color{red}{E[y_{1i} - y_{0i} \mid D_i = 1]} \\
&= \color{red}{E[y_{0i} \mid D_i = 1]} 
   + \color{red}{E[\tau_i \mid D_i = 1]}
\end{aligned}
  $$
Entonces, tomando la diferencia entre ambos grupos, $E[y_i \mid D_i = 1]- E[y_i\mid D_i =0]$, llegamos al resultado que habíamos anunciado antes: 
$$
\begin{aligned}
  E[y_i \mid D_i = 1]- E[y_i\mid D_i =0] = \underbrace{E[y_{1i} - y_{0i} \mid D_i=1]}_{\text{ATT}} + \underbrace{E[y_{0i} \mid D_i=1] - E[y_{0i}\mid D_i=0]}_{\text{Sesgo de Seleccion}}
\end{aligned}
$$
Con ello, podemos observar que el **sesgo** proviene del hecho de que aquellos que buscan tratamiento ($D_i=1$), tienen características diferentes. Por otro lado, nos encontramos con el **ATT**. El **_Average treatment effect on the treated_** (ATT) es el *efecto promedio* del tratamiento para los individuos tratados. Si los efectos son heterogéneos en la población, este es un afecto causal diferente al efecto promedio en la población (ATE). Luego lo veremos. Pero ahora, pasemos al segundo bloque para seguir profundizando. 


# Bloque 2: Experimentos 

## Experimentos y causalidad 

Con datos observacionales, la identificación del efecto causal es complejo, aunque no imposible. Pero conviene partir cómo se captura esto con datos experimentales. Nuevamente, esto es para seguir con el concepto de **ideal experimental**: lo ideal será ahcer un un experimento donde solo modificamos $X$, dejando todo lo demás constante (*ceteris paribus*), para obser el efecto de la variación de $X$ *en* $Y$. Para algunos tipos de preguntas, pues, podemos hacer experimentos con **grupos de control aleatorio**: **RCT**, por sus cifras en inglés: *Randomized Control Trials*. 

**Randomized Control Trials** (RCT's): la idea de los RCT's proviene de la medicina, por ejemplo, tomando los tipos de investigaciones para medir la efectividad de un nuevo fármaco o vacuna. En este tipo de experimentos, se elige un grupo de pacientes aquejados por la enfermedad que el nuevo fármaco pretende curar. Entonces, se podría realizar lo siguiente:

  - Se asigna al azar a cada paciente a uno de tres grupos:
    - el fármaco nuevo
    - el fármaco en uso
    - un placebo (sin contenido medicinal (y sin informar cuál es cuál))
    
  - Se compara la respuesta promedio de los tres grupos al tratamiento  
  
Entonces, tenemos que los pacientes no saben en qué grupo están, e idealmente los que administran los fármacos idealmente tampoco deberian saber a qué grupo pertenece cada paciente. Con ello, se podría formar un caso típico de RCT. Y, en el caso de que la respuesta de los tratados con el nuevo fármaco es significativamente mejor que la de los restantes grupos, se podría concluir que el nuevo fármaco es efectivamente mejor que el anterior. 

En economía también se han realizado RCT's. Entre algunos de ellos: 

  -  National Supported Work Demonstration, 1975-1979
  -  Negative Income Tax Experiments, 1968-1979
  -  RAND Health Insurance Experiment, 1971-1986
  -  Moving to Opportunity, 1994-2010
  -  Tennessee STAR Experiment, 1985-1998
  -  Perry Preschool Program, 1960s
  -  Progresa/Oportunidades en Mexico, 1997-1999 
  - También hay muchos ejemplos en economía del desarrollo ([Esther Duflo: Experimentos sociales para luchar contra la pobreza](https://www.youtube.com/watch?v=0zvrGiPkVcs))
  

## Asignación aleatoria

Entendiendo la idea de los RCT's, veamos un concepto fundamental de los diseños experimentales. Pero antes, retomemos un poco. Hasta aquí tenemos lo siguiente: 

1. Un experimento define a un grupo de tramiento y otro de control. De aquí existen dos resultados posibles: 

  - Resultado con tratamiento $y_{1i}$
  - Resultado sin tratamiento $y_{0i}$

2. Solo podemos observar uno de los dos resultados para $i$. Para ello, definimos la asignación de tratamiento con una variable de tratamiento $D_i$, que nos permite identificar: 
$$
y_i = 
\begin{cases}
  y_{1i}, & \quad \text{si } D_i =1\\
  y_{0i}, & \quad \text{si } D_i =0\\
\end{cases}
$$
3. El efecto causal del tratamiento es
$$
\tau_i =y_{1i}-y_{0i}
$$
pero no se puede observar directamente $\tau_i$. 
4. Dado que no se puede observar $\tau_i$, se dfine el efecto promedio del tratamiento (ATE) como 
$$
E[\tau_i] = E[y_{1i}-y_{0i}] 
$$
y el efecto promedio *sobre* los tratados (ATT) como
$$
E[\tau_i \mid D_i =1] = E[y_{1i}-y_{0i}\mid D_i =1] 
$$
5. Al tratar con el problema econométrico, recordemos qué pasaba cuando tomabamos la diferencia entre ambios grupos: 
$$
E[y_{1i} \mid D_i = 1] - E[y_{0i} \mid D_i =0]
$$
que es equivalente a 
$$
E[y_{1i} \mid D_i = 1] - E[y_{0i} \mid D_i = 1] + E[y_{0i} \mid D_i = 1] - E[y_{0i} \mid D_i = 0]
$$
donde $E[y_{1i} \mid D_i = 1]- E[y_{0i} \mid D_i = 1]$: ATT; y $E[y_{0i} \mid D_i = 1]- E[y_{0i} \mid D_i = 0] \neq 0$: Sesgo de selección (SS). Entonces teníamos que
$$
E[y_{1i} \mid D_i = 1]-E[y_{0i} \mid D_i = 0] = ATT+ SS
$$
No obstante, la comparación del promedio de los grupos **no** nos da *per se* el efecto del tratamiento (de hecho, no siempre es cero). Si no que, esto lo obtendremos con la aleatorización. 

### La Solución Experimental: Por qué funciona la Aleatorización

Como vimos en la sección anterior, el sesgo de selección surge porque las personas se "autoseleccionan" en el tratamiento basándose en sus características (y por ende, en sus resultados potenciales). Quienes van al hospital ($D_i=1$) tienen, *de base*, una salud ($Y_{0i}$) peor que quienes no van. La asignación aleatoria (Random Assignment) resuelve este problema de raíz. ¿Cómo? **Desvinculando el tratamiento de las características del individuo**.

En un RCT, la asignación del tratamiento $D_i$ es decidida por un mecanismo aleatorio (una moneda, una lotería, un generador de números aleatorios). Esto implica una propiedad estadística fundamental descrita por [Angrist y Pischke (2008)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf): **la independencia**:
$$\{Y_{1i}, Y_{0i}\} \perp \!\!\! \perp D_i$$

Esto se lee así: los resultados potenciales son independientes del estatus de tratamiento. En palabras simples: el hecho de que seas asignado al grupo de tratamiento o al de control no tiene **nada** que ver con tu salud previa, tu motivación, tu inteligencia o tu nivel socioeconómico. Es puro azar. Esta independencia es la herramienta más poderosa de la econometría experimental. Nos permite afirmar que, en promedio, los individuos del grupo de control son idénticos a los del grupo de tratamiento *antes* de la intervención.

#### La Derivación Formal

Esta independencia nos permite hacer una "magia" matemática. Recordemos nuestra descomposición de la diferencia de medias observada:

$$
\underbrace{E[Y_i | D_i=1] - E[Y_i | D_i=0]}_{\text{Diferencia Observada}} = \underbrace{E[Y_{1i} | D_i=1] - E[Y_{0i} | D_i=1]}_{\text{ATT}} + \underbrace{E[Y_{0i} | D_i=1] - E[Y_{0i} | D_i=0]}_{\text{Sesgo de Selección}}
$$

Bajo aleatorización, el término de sesgo de selección desaparece. Siguiendo a [A&P (2008)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf), la lógica es la siguiente: dado que $D_i$ es independiente de $Y_{0i}$, el promedio del resultado potencial "sin tratamiento" ($Y_{0i}$) es estadísticamente idéntico en ambos grupos.

$$E[Y_{0i} | D_i = 1] = E[Y_{0i} | D_i = 0] = E[Y_{0i}]$$

Esto es lo que A&Pe llaman la capacidad de **"intercambiar"** (*swap*) términos. Podemos usar el resultado observado del grupo de control ($E[Y_{0i} | D_i=0]$) como un contrafactual perfecto para el grupo de tratamiento.

#### El Resultado: ATE = ATT

Si el sesgo de selección es cero, la ecuación se simplifica dramáticamente:

$$
\begin{aligned}
E[Y_i | D_i=1] - E[Y_i | D_i=0] &= E[Y_{1i} | D_i=1] - E[Y_{0i} | D_i=1] \\
&= E[Y_{1i} - Y_{0i} | D_i=1] \\
&= E[Y_{1i} - Y_{0i}]
\end{aligned}
$$

Bajo aleatorización, la diferencia de medias simple no solo recupera el Efecto Promedio en los Tratados (ATT), sino que, como la muestra es representativa y la asignación es aleatoria, este es igual al **Efecto Promedio del Tratamiento (ATE)** poblacional [(Angrist y Pischke, 2008)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf).

::: {.callout-tip appearance="minimal"}
**Intuición Económica:**
En el ejemplo del hospital de A&P, si forzáramos a una muestra aleatoria de la población a ir al hospital (independientemente de si están enfermos o no), eliminaríamos el hecho de que "los enfermos buscan tratamiento". Así, compararíamos la salud de un grupo promedio hospitalizado versus un grupo promedio no hospitalizado. La diferencia sería, indiscutiblemente, el efecto causal de la atención médica.
:::

En suma, si $D_i$ es asignado al azar, entonces es independiente de $y_i$, tal que 
$$
E[y_{1i} \mid D_i = 1] = E[y_{1i} \mid D_i = 0] = E[y_{1i}] .
$$
Luego, teníamos que el efecto del tratamiento es el siguiente: 
$$
E[y_{1i}\mid D_i =1]-E[y_{0i}\mid D_i =0] = ATT 
$$
por lo que ahora: 
$$
E[y_{1i}\mid D_i =1] - E[y_{0i}\mid D_i =1] = E[y_{1i}-y_{0i}].
$$
Es decir, que el ATT coincide con el ATE. Además, vale la pena mencionar que el *estimador* de ATE se puede calcualr como diferencia de medias:
$$
\bar{Y}\mid D_i = 1 - \bar{Y}\mid D_i = 0
$$
Por último, una sintesis hasta aquí de lo que llevamos de manera esquemática: 

```{mermaid}
flowchart LR

    %% Nodos principales
    P["Población"]
    M["Muestra"]
    GT["Grupo tratamiento"]
    GC["Grupo control"]

    %% Nodos de texto (etiquetas en cajas)
    T1["Muestreo Aleatorio<br/>Validez Externa"]
    T2["Asignación Aleatoria<br/>Validez Interna"]
    T3["Asignación Aleatoria<br/>Validez Interna"]

    %% Conexiones
    P --> T1 --> M
    M --> T2 --> GT
    M --> T3 --> GC

    %% Estilo de cajas principales
    classDef main fill:#f6eeee,stroke:#666,stroke-width:1px,color:#8b0000
    class P,M,GT,GC main

    %% Estilo de cajas de texto intermedias
    classDef label fill:#ededed,stroke:#ededed,color:#8b0000,font-size:12px
    class T1,T2,T3 label

```


## Experimentos aleatorizados: Proyecto STAR 


Algo que no hemos mencionado hasta ahora: para un experimento aleatorio, en general vamos a necesitar un número lo suficientemente **grande** de personas en cada grupo. Por ejemplo, si tenemos solo 1 personas en cada grupo, es muy probable que estas dos personas difieran en cosas distintas generando sesgo por selección. En cambio, si tenemos grupos con un $n$ lo suficientemente grande e individuos elegidos al azar, entonces, aunque *cada* individuo sea diferente, la mayoría de las características serán similares *en promedio*. A esto también le llamamos *en expectativa*, pues calculamos el valor esperado por notación generalmente como ya vimos. 

Pero, ¿cómo sabemos que el tamaño $n$ influye de tal manera? Bueno, por la propiedad estadística de la **Ley de los Grandes Números**: el promedio muestral se acerca al promedio poblacional a medida que aumenta el tamaño de la muestra. El promedio poblacional se llama *esperanza matemática*, $E[y]$. Entonces, $\bar{y} \to E[y]$. 

Luego de aleatorizar, se debe chequear que los grupos de tratamiento y de control no tinene diferencias en variables observables (características y variable de resultado), **previo a la intervención**. Veamos cómo ocurre esto con una investigación empírica real: el Proyecto STAR (*Student/Teacher Achievement Ratio*), ejecutado durante los 80s en Tennessee (US), donde se redujo el tamaño de la clase de pre-escolares. La asignación aleatoria de estudiantes en 3 grupos

  * Tratamiento: 1) Clases pequeñas (13-17 alumnos).
  * Control: 2) Clases regulares (22-25 alumnos) y un asistente de profesor a tiempo parcial; o 3) clases regulares con un asistente de profesor a tiempo completo.
  
  
Así, una de las primeras preguntas que hay que plantearse sobre un experimento aleatorio es "si la aleatorización ha logrado equilibrar con éxito las características de los sujetos entre los diferentes grupos de tratamiento" [(Angrist y Pischke, 2008, p. 14, *traducción propia*)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf). Para ello, se suele comparar resultados previos al tratamiento y/u otras covariables. Los datos de STAR, no obstante, no incluyen las puntuaciones de las pruebas previas al tratamiento, pero es posible examinar caracteristicas personales como la raza y la edad. A&P muestran la siguiente tabla, en la cual debemos verificar que la aleatorización funcionó. Las características pre-tratamiento deben ser iguales entre grupos:

```{r img-star-balance}
#| echo: false
#| fig-cap: "Tabla de Balance Proyecto STAR"
#| out-width: "80%"

knitr::include_graphics("images/star_balance.png", error = FALSE)
```

Entonces, el "tratamiento" serían las clases pequeñas (Columna "*Small*") y los dos controles diferenciados por clases regulares (igual de grandes que antes), pero con la diferenciación del profe a tiempo completo o parcial. Las variables relevantes en verdad son las 3 primeras: 1. Almuerzo gratis, 2. Blanco/asiático y 3. Edad en 1985. Se presentan medias, por lo que sería, por ejemplo, para 1: 47% de los alumnos recibían almuerzo gratuito en salas pequeñas, 48% en regulares y 50% en regulares con profe asistente. Como vemos, coinciden los valores en casi todas. Al rededor del 50% tiene almuerzo gratis en todas los tipos de salas (nivel socioeconómico (bajo) similar), al rededor de 2/3 son blancos o asiaticos y la edad promedio en 1985 era casi de 5 años y medio. El joint $p-$*value* (es un $F-$*test*) indica si hay diferencias significativas estadísticamente habblando. COmo vemos, ninguna $p<0.05$, por lo que no hay diferencias signidicativas entre los grupos de control y el tratado. Esto indica que son grupos con características similares^[La atrición son los casos perdidos porque se cambiaron de colegio o cualquier otro motivo].

Por lo tanto, son grupos balanceados. Además, dado que "la aleatorización elimina el sesgo de selección, la diferencia en los resultados entre los grupos de tratamiento refleja el efecto causal medio del tamaño de la clase (en relación con las clases normales con un asistente a tiempo parcial)" [(Angrist y Pischke, 2008, p. 15, *traducción propia*)](https://newblankets.org/worth_a_look/Mostly%20Harmless%20Econometrics.pdf). En la práctica, la diferencia en las medias entre los grupos de tratamiento y control puede obtenerse a partir de una regresión de las puntuaciones de las pruebas sobre variables *dummy* para cada grupo de tratamiento, un punto que se trata aquí con una tabla, pero que después profundizaremos con más detenimiento. En cualquier caso, la tabla es la siguiente (solo para adelantar, luego la analizamos bien):

```{r img-star-balance-regression}
#| echo: false
#| fig-cap: "Estimaciones experimentales del efecto de la asignación del tamaño de clase en los puntajes de los exámenes"
#| out-width: "80%"

knitr::include_graphics("images/regression-to-balance.png", error = FALSE)
```

## Ventajas y limitaciones de los experimentos aleatorizados

Antes de pasar al bloque de regresión e inferencia, que es donde retomaremos la tabla anterior, conviene decir algunas cosas. Si bien los RCTs son considerados el *Gold Standard* para la identificación causal debido a su capacidad para asegurar la **validez interna**, no están exentos de desafíos prácticos y teóricos. No basta con aleatorizar; el investigador debe ser consciente de las barreras que pueden comprometer tanto la integridad del experimento como su utilidad para el diseño de políticas públicas.

### El poder de la aleatorización (Ventajas)

La principal fortaleza de un RCT es que la asignación exógena del tratamiento permite "limpiar" la estimación de ruidos estadísticos que suelen invalidar los estudios observacionales:

1.  **Eliminación del Sesgo de Selección:** eomo demostramos formalmente, al asignar aleatoriamente garantizamos que $cov(D_i, \eta_i) = 0$. Esto elimina la correlación sistemática entre el tratamiento y las características observadas (y, crucialmente, las **no observadas**) de los participantes.
2.  **Ausencia de Causalidad Inversa:** dado que es el investigador quien impone el tratamiento exógenamente, por definición, eliminamos la posibilidad de que sea la variable resultado $Y$ la que cause $D$.
3. **Permiten variar distintos parámetros**, en lugar de enfrentar el efecto de múltiples cambios de política que ocurren simultáneamente. Y eso también nos permite probar tratamientos que no serían factibles en la realidad.
4.  **Transparencia:** Los resultados de un experimento bien ejecutado son fáciles de comunicar, ya que se basan en una comparación directa de promedios entre grupos, sin necesidad de modelos estructurales complejos.

### Desafíos y Amenazas (Limitaciones)

No obstante, llevar un experimento al "mundo real" presenta limitaciones severas que clasificamos en tres dimensiones:

#### Restricciones estructurales y éticas

El costo monetario y político de un RCT es masivo. Además del financiamiento, existen preguntas económicas que simplemente **no pueden** responderse mediante experimentos por razones éticas (ej: ¿cuál es el efecto de la contaminación en la salud infantil?) o técnicas. Esto último, es importante, porque se podrán tener todos los recursos del mundo, pero a veces son inviables porque las personas tratadas no quieren exponerse a un experimento aleatorio de tal naturaleza.

#### Amenazas a la Validez Interna

Incluso con un diseño robusto, la ejecución puede fallar reintroduciendo sesgos: 

* **Problemas de implementación**: los problemas de implementación pueden ocurrir en un RCT. Por ejemplo, puede existir una mala práctica en la asignación aleatoria, generando que $\mbox{cov}(D_i, u_i) \neq 0$. A su vez, pueden ocurrir incumplimientos de protocolos: el grupo de tratamiento no recibe todo el tratamiento y el grupo de control recibe parte del tratamiento (*partial compliance*). 
* **Sesgo de Deserción (Attrition):** si la pérdida de participantes no es aleatoria (ej: si los más enfermos en el grupo de control abandonan el estudio), la comparación final estará sesgada. También puede ocurrir que no aleatoriamente parte de la muestra no responda entrevistas o al tratamiento. 
* **Sesgo de desempeño:** los participantes pueden cambiar su conducta por saberse observados (Efecto Hawthorne) o el grupo de control puede buscar activamente sustitutos al tratamiento (Sesgo de sustitución), sesgando el efecto hacia cero^[En mediciana, es más común realizar experimentos doble ciego para sortear esta dificultad].
* **Sesgo de sustitución**: el grupo de control puede buscar tratamientos sustitutos porque se les negó el tratamiento. Es por eso que se utilizan placebos. Mientras la muestra esté menos consciente de si se le asignó o no el tratamiento, mejor. 

#### Amenazas a la Validez Externa

Un experimento puede ser válido para su muestra, pero su capacidad de generalización es limitada si el efecto del tratamiento difiere entre contextos geográficos o periodos de tiempo. Además, resultados a pequeña escala pueden no mantenerse al masificarse debido a **efectos de equilibrio general**.

### Tipología de Efectos del Tratamiento {-}

Cuando los efectos del tratamiento son heterogéneos, debemos ser precisos sobre qué estamos midiendo exactamente:

::: {.r-stack .border .p-3 .rounded style="background-color: #f8f9fa; border-color: #69000C !important; border-width: 2px !important;"}
**Efectos del Tratamiento: Definiciones Clave**

1.  **ATE (Average Treatment Effect):** Es el efecto promedio esperado si asignáramos a un individuo aleatorio de la población al tratamiento.
    $$ATE = E[Y_{1i} - Y_{0i}]$$
2.  **ATT (Average Treatment Effect on the Treated):** Es el efecto promedio para quienes efectivamente recibieron el tratamiento.
    $$ATT = E[Y_{1i} - Y_{0i} \mid D_i = 1]$$
3.  **$ATE(x)$ (Efecto Condicional):** El efecto promedio para un subgrupo específico con características $x$.
    $$E[Y_{1i} - Y_{0i} \mid X_i = x]$$
:::

En un experimento con **asignación aleatoria perfecta**, el tratamiento es independiente de los resultados potenciales, lo que implica que el grupo tratado es estadísticamente idéntico al grupo de control antes de la intervención. En este escenario ideal:
$$ATE = ATT$$

## El problema del cumplimiento (Take-up)

En la práctica, la **asignación** al tratamiento no siempre equivale a la **recepción** del mismo (Take-up). Si existe una proporción de individuos que no toma el tratamiento asignado, estamos bajo **"imperfect compliance"**.

Puesto que la decisión de tomar el tratamiento ($T_i$) ya no es aleatoria (depende de la voluntad o características del individuo), comparar a quienes se trataron contra quienes no reintroduce el **sesgo de selección**. Por esta razón, en estos contextos se estima el **ITT (Intention-to-Treat)**, que mide el efecto de haber sido *asignado* al tratamiento, independientemente de la adopción final.

```{r tabla-resumen-efectos}
#| echo: false
#| warning: false

data.frame(
  Concepto = c("ATE", "ATT", "ITT"),
  Definicion = c("Efecto promedio poblacional", "Efecto promedio en quienes se tratan", "Efecto de ser asignado al tratamiento"),
  `Uso Principal` = c("Inferencia general", "Evaluacion de impacto directo", "Politica publica con adopcion parcial")
) |> 
  gt() |> 
  tab_header(title = md("**Resumen de Estimadores de Impacto**")) |> 
  tab_options(
    heading.background.color = "#69000C",
    column_labels.background.color = "#69000C",
    table.border.top.color = "#69000C",
    table.border.bottom.color = "#69000C",
    source_notes.font.size = px(12)
  )

```



# Bloque 3: Regresión e Inferencia

Volvamos a la tabla anterior, que si habíamos mencionado, pero para retomar bien la que no mencionamos:  

```{r img-star-balance2}
#| echo: false
#| fig-cap: "Tabla de Balance Proyecto STAR"
#| out-width: "80%"

knitr::include_graphics("images/star_balance.png", error = FALSE)
```

Lo que se tiene que analizar aquí es **cuál es el efecto de estar en una clase pequeña respecto a estar en una clase grande/regular (sin tratamiento) y sin profesor asistente**. En principio, lo primero que podemos mencionar es cuál es el efecto de tener una clase pequeña sobre el desempeño en la prueba. Vemos que en la variable de resultados, `6. Percentile score in kindergarten`, una clase pequeña puntua 54,7 --columna *small*--, mientras que una regular 49,9 --columna *regular*--. Ese sería el efecto bruto de estar en una clase de $\approx$ 15 personas, respecto a una de 23 app. Notamos, además, que agregar un asistente/ayudante, *Regular/Aide*, solo aumenta respecto a la *Regular* en 0,01 el puntaje en la variable re resultados. 

Si esto estuviera desbalanceado, se puede utilizar regresiones para mejorar esta predicción. De inmediato lo veremos, pero *ya* con esto, dado que es un RCT, solo comparando medias tenemos una buena predicción del efecto *causal* de estudiar en una clase pequeña respecto a una regular o regular con asistente. Es decir, como es un experimento aleatorizado, el efecto promedio de estudiar en una clase pequeña (tratamiento) respecto a una regular o, más específicamente, sin aplicarle el tratamiento de disminución de alumnos (control), ya nos indica una diferencia en el puntaje de la variable de resultado y, por tanto, la magnitud del efecto de estudiar en una aula con menos alumnos. La magnitud de ese efecto es, por tanto, la diferencia entre estas medias. Así pues, nuestro estimador es
$$
\hat{\tau} = \bar{Y}_1 - \bar{Y}_0
$$
Además, tenemos que su error estándar está dado por
$$
\mbox{SE}(\hat\tau) = \sqrt{\frac{s^2_1}{n_1} +\frac{s^2_0}{n_0}}
$$
donde $s_1^2, s_0^2$ son las varianzas muestrales de los grupos tratados y de control, respectivamente; y $n_1, n_0$ sus tamaños muestrales. Por lo tanto, con ello también podemos obtener una medida de confianza de nuestro estimador.

Entonces, si los grupos están bien balanceados y el RCT está bien hecho, con esto simplemente nos alcanza. Como vemos, tenemos un estimador del efecto causal, $\hat\tau$, y una medida de precisión, $\mbox{SE}(\hat\tau)$. Y, además, es algo muy simple de comunicar, entendible para todo público y riguroso científicamente. Ahora bien, ¿podemos hacer algo más realizando un análisis de regresión? Sí, en efecto podemos hacerlo. 



## Análisis de regresión en experimentos 


¿Para qué vamos a usar regresiones en experimentos aleatorizados? En primer lugar, el estimador $\hat \tau$ podríamos estimarlo con una regresión simple. ¿Cuál sería esa regresión? Tendríamos que regresar nuestra variable de resultados, $y_i$, es decir `Percentile score in kindergarten`, contra una dummy, $D_i$, que indica si se está o no en una clase pequeña, esto es, si recibió o no tratamiento. Entonces, si suponemos que ele fecto de un tratamiento es igual para todos los individuos, se tiene que 
$$
y_{1i}-y_{0i} = \tau
$$
Luego, con efecto constante, re escribimos esto como 
$$
\begin{aligned}
  y_i &= y_{0i}+ (y_{1i}- y_{0i})D_i\\
  &=y_{0i} + \tau D_i + E[y_{0i}]-E[y_{0i}]\\
  &= E[y_{0i}]+\tau D_i + (y_{0i}- E[y_{0i}])\\
  &= \alpha + \tau D_i + \eta_i
\end{aligned}
$$
Por lo tanto, nuestra regresión a estimar sería 
$$
y_i = \alpha + \tau D_i + \eta_i
$$
donde, si se estima, entonces $\hat\alpha$ es el intercepto: cuando el tratamiento es cero. Y el $\hat \tau$ sería la diferencia entre los tratados y los no tratados. Lo que tenemos, por tanto, es que el valor esperado para tratados y no tratados sería: 
$$
\begin{aligned}
  E[y_i \mid  D_i = 1] &= \alpha + \tau + E[\eta_i | D_i = 1]\\
  E[y_i \mid  D_i = 0] &= \alpha + E[\eta_i | D_i = 0]
\end{aligned}
$$
Entonces,
$$
  E[y_i \mid D_i =1]- E[y_i \mid D_i =0] =\tau + E[\eta_i \mid D_i =1]- E[\eta_i \mid D_i =0]
$$
Con asignación aleatoria, basta realizar una regresión de $y_i$ sobre $D_i$:
$$
E[y_i\mid D_i = 1]- E[y_i \mid D_i = 0] = \tau
$$
Nos da exactamente lo mismo. No obstante, el uso de regresores adicionales puede contribuir a generar estimadores más precisos en dos situaciones: 

  1. Cuando el diseño es aleatorio condicional a otra variable (Proyecto STAR: aleatorización dentro de escueal y no entre escuelas, por que se introduce un efecto fijo por escuela)
  
  2. Regresores disminuyen el error estándar poque tienen poder explicativo sobre $y_i$, aún cuando las pruebas de balance indiquen diferencias *no significativas*. 
  
  
Es más, si vemos la tabla 2.2.2. que dejamos pendiente, que es justamente un modelo de regresión del experimento, tenemos los mismos resultados (aunque agregaron más controles después): 


```{r img-star-balance-regression2}
#| echo: false
#| fig-cap: "Estimaciones experimentales del efecto de la asignación del tamaño de clase en los puntajes de los exámenes"
#| out-width: "80%"

knitr::include_graphics("images/regression-to-balance.png", error = FALSE)
```

Como vemos, en la primera tabla la diferencia en la variable de resultados `Percentile score in kindergarten` entre el puintaje promedio de estar en una clase pequeña respecto a una regular es 
$$
\hat \tau = \bar{Y}_1- \bar{Y}_0 = 54.7-50.0 = 4.7
$$
En el modelo de regersión, en la columna 1 donde no se han agregado controles, la diferencia es:
$$
\hat \tau = 4.82-0.12 = 4.7
$$
Esto es evidente, porque lo que indica el modelo de regresión en el $\widehat{\text{Small class}} = 4.82$ es que estar en una clase pequeña (tratamiento) sube el puntaje promedio en 4.82 respecto de no estarlo (control). En cambio, el estimador $\widehat{\text{Regular}} = 0.12$ indica que aumenta en promedio solo 0.12. La diferencia es el efecto causal, que es lo mismo que calcular la diferencia entre las medias de `Percentile score in kindergarten` si se aplicó o no el tratamiento.   

Entonces, en efecto, no hay diferencia entre restar las medias en un RCT, y aplicar un modelo de regresión *simple* al RCT. Pero, como  ya vimos, no significa que sea inútil aplicar el modelo de regresión al RCT, pues nos sirve para ir agregando controles de manera más efectiva, además de para ponderar valores si el experimento está desbalanceado.

Lo que tenemos es, pues, todo lo siguiente. Dado que ya demostramos que si el efecto es constante para todos los individuos, entonces podemos escribir 
$$
  y_i = \alpha + \tau D_i +  \eta_i
$$
y que, con $D_i$ aleatorio, entonces se cumple $E[\eta_i \mid D_i ] = 0$, luego se cumplen los supuestos de MCO y obtenemos un estimador insesgado de $ATE(\tau)$. Y, entonces, tenemos que 
$$
\hat \tau = \widehat{ATE} \quad \text{ y } \quad E[\hat\tau] = ATE 
$$
De tal modo, no es necesario incluir controles para obtener un estimador ATE insesgado, *pero* podemos incluir controles para disminuir la varainaza del error, para ponderar mejor valores, etc. Respecto a disminuir la varianza, que nos servirá incluido cuando el experimento esté bien balanceado (ergo, siempre será útil aplicar un modelo de regresión), supongamos que agregamos $X_i$, tal que 
$$
\begin{aligned}
  y_i &= \alpha + \tau D_i + \beta X_i - \beta X_i + \eta_i\\
  y_i &= \alpha + \tau D_i + \beta X_i+  \nu_i
\end{aligned}
$$
donde $\nu_i = \eta_i - \beta X_i$ y, por tanto, si $\beta \neq 0$, entonces la varianza del término de error disminuye. En ello reside la utilidad de realizar un análisis de regresión a un RCT incluso cuando el experimento está bien balanceado. En el fondo, siempre será útil, a pesar de que con una diferencia de medias ya estaremos obteniendo, y rigurosamente, el efecto causal de nuestro tratamiento. 

Otra cuestión útil, además de la reducción de la varianza del término de error, es que añadir controles también evita posibles sesgos si el tratamiento depende de otra variable. Por ejemplo, supongamos que $X_i$ depende del tratamiento $D_i$. La ecuación a estimar, por tanto, es
$$
y_i = \alpha + \tau D_i + \beta X_i + u_i
$$
Supongamos que $y_i$ es salarios, $D_i$ si se recibe capacitación y $X_i$ si se consigue empleo después de la capaciatación. Entonces, al agregar $\beta X_i$, se estima el impacto de haber recibido la capacitación, el tratamiento, *controlando* por haber obtenido un empleo. Entonces, no solo reduce la varianza del término de error, sino que en el fondo mejora la específicación de nuestro modelo muchas veces el hecho de agregar variables de control. 

Muchas veces también los controles nos sirven para chequear **la calidad de la aleatorización**. Así, se puede hacer una prueba de balance con test de media, o bien, correr la siguiente regresión:
$$
  D_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + \varepsilon_i
$$
y aplicar un Test F: $H_0 : \beta_1 =  \beta_2 = \ldots = \beta_m =0$. Ello nos indicaría si las variables de control no están relacionadas con la asignación del tratamiento. 


## Asignación aleatoria condicional

En un experimento aleatorizado, la asignación al tratamiento es *independiente* de los resultados potenciales y es una función conocidas de los covariables. Hay tres formas principales: 

  - Asignación completamente aleatoria
  - Aleatorización estratificada (aleatorización dentro de un número finito de estratos)
  - Aleatorización por conglomerados (aleatorización a nivel de *clusters*)


El siguiente esquema resume la diferencia entre la aleatorización estratificada a la por conglomerados: 

```{r stratified-vs-clusters}
#| echo: false
#| fig-cap: "Aleatorización estratificada vs por conglometerados (*clustering*)"
#| out-width: "80%"

knitr::include_graphics("images/stratified-vs-cluster-sampling.png", error = FALSE)
```

En la práctica, la aleatorización rara vez es "simple" o completamente al azar sobre toda la población. A menudo, el investigador posee información previa sobre los sujetos o enfrenta restricciones logísticas que lo obligan a utilizar un mecanismo de **asignación aleatoria condicional**. En este diseño, la probabilidad de recibir el tratamiento es una función conocida de ciertas covariables observadas.

Como se observa en la @stratified-vs-clusters, la arquitectura del muestreo y la asignación cambia drásticamente según cómo agrupemos a las unidades.

### Aleatorización Estratificada (Stratified Randomization)

Este método consiste en dividir a la población en $G$ estratos definidos por variables exógenas (como género, edad o nivel socioeconómico) y realizar una aleatorización independiente dentro de cada estrato.

* **Lógica:** Buscamos asegurar que grupos pequeños pero importantes estén representados proporcionalmente tanto en el grupo de tratamiento como en el de control.
* **Ventaja Técnica:** Mejora la eficiencia estadística al evitar "vectores de asignación no informativos" (por ejemplo, casos accidentales donde todos los hombres terminen en el grupo de control y todas las mujeres en el de tratamiento).
* **Ejemplo en STAR:** La aleatorización se realizó **dentro de cada escuela**. Esto garantiza que las características específicas de una escuela (infraestructura, calidad docente promedio) no sesguen la comparación entre clases pequeñas y grandes.

### Aleatorización por Conglomerados (Cluster Randomization)

A diferencia de la anterior, aquí la unidad de aleatorización no es el individuo, sino un grupo pre-existente o "cluster".

* **Lógica:** Todos los individuos pertenecientes a un mismo cluster (ej: una sala de clases, una aldea o una manzana) reciben el mismo estatus de tratamiento.
* **Motivación:** Se suele utilizar por razones logísticas o para minimizar **spillovers** (interferencias) entre vecinos que harían inviable tratar a unos y a otros no dentro de un mismo espacio.
* **Ejemplo en STAR:** Si bien la asignación fue dentro de escuelas, cada sala de clase constituye un **cluster**. Esto tiene implicancias críticas para la inferencia: los errores estándar deben ajustarse (closterizarse), ya que los resultados de los alumnos dentro de una misma sala están correlacionados entre sí.

::: {.r-stack .border .p-3 .rounded style="background-color: #f8f9fa; border-color: #69000C !important; border-width: 2px !important;"}
**Diferencia Fundamental: Representatividad vs. Unidad de Implementación**

Mientras que la **estratificación** busca asegurar que la muestra sea un "espejo" de la diversidad poblacional (tomando sujetos de todos los colores en la imagen), el **clustering** selecciona grupos completos (bloques de color), facilitando la implementación pero sacrificando, en ocasiones, poder estadístico por la correlación intracluster.
:::

```{r tabla-comparativa-muestreo}
#| echo: false
#| warning: false

data.frame(
  Dimension = c("Unidad de asignación", "Objetivo principal", "Efecto en precisión", "Inferencia"),
  Estratificada = c("Individuo (dentro del grupo)", "Equilibrio y representatividad", "Aumenta la precisión (reduce SE)", "Modelar con Efectos Fijos"),
  Conglomerados = c("Grupo o Cluster completo", "Viabilidad logística / Spillovers", "Suele disminuir la precisión", "Ajustar errores por cluster")
) |> 
  gt() |> 
  tab_header(title = md("**Comparación de Diseños Condicionales**")) |> 
  tab_options(
    heading.background.color = "#69000C",
    column_labels.background.color = "#69000C",
    table.border.top.color = "#69000C",
    table.border.bottom.color = "#69000C",
    source_notes.font.size = px(12)
  )
```






## SUTVA (Stable Unit Treatment Value Assumption)

Asumimos que no hay interferencia entre unidades: el tratamiento de $i$ no afecta a $j$.

  * *Violaciones*: Efectos pares (spillovers), efectos de equilibrio general.

## Pruebas de Hipótesis

  * **Muestras grandes**: Test-t asintótico estándar.
  * **Muestras pequeñas**: Test Exacto de Fisher (permutaciones).


# Referencias

  * Angrist & Pischke (2008). *Mostly Harmless Econometrics*, Cap. 2-3.
  * Material del curso "Econometría Aplicada I", FEN U. Chile (2025).

